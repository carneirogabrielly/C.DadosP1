{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Alison Araujo\n",
    "\n",
    "Nome: Gabrielly Carneiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading word_tokenize: Package 'word_tokenize' not\n",
      "[nltk_data]     found in index\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'deprecated' from 'typing_extensions' (C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\typing_extensions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\confection\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelField\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m from ._internal._annotated_handlers import (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\dataclasses.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_decorators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_typing_extra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_dataclasses\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pydantic_dataclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\_internal\\_config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfigDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtraValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJsonEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJsonSchemaExtraCallable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPydanticUserError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_migration\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetattr_migration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExtra\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_Extra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\deprecated\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'deprecated' from 'typing_extensions' (C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\typing_extensions.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8812\\4060088076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# !python -m spacy download pt_core_news_sm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pt_core_news_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# set library-specific custom warning handling before doing anything else\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\errors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\compat.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mabout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# fmt: off\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcatalogue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mconfection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mconfection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVARIABLE_RE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConfigValidationError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPromise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\confection\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelMetaclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtra\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelMetaclass\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelField\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m from ._internal._annotated_handlers import (\n\u001b[0;32m     15\u001b[0m     \u001b[0mGetCoreSchemaHandler\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mGetCoreSchemaHandler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\dataclasses.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataclass_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_decorators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_typing_extra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_dataclasses\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pydantic_dataclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_migration\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetattr_migration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\_internal\\_config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSelf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfigDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtraValues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJsonEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJsonSchemaExtraCallable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPydanticUserError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarnings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPydanticDeprecatedSince20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_migration\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetattr_migration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExtra\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_Extra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydantic\\deprecated\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'deprecated' from 'typing_extensions' (C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\typing_extensions.py)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('word_tokenize')\n",
    "stopwordsdic = stopwords.words('portuguese')\n",
    "\n",
    "!pip install spacy\n",
    "!python -m spacy download pt_core_news_sm\n",
    "\n",
    "from spacy import load\n",
    "nlp = load('pt_core_news_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('dados_treino.xlsx')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('dados_teste.xlsx')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na primeira etapa, de classificação manual, consideramos três targets para os reviews: Acionável, Direcionável e Não Acionável. \n",
    "\n",
    "- Acionável: para ser considerado \"acionável\" (\"A\") o review deve ser passível de alguma ação pela Amazon, ou seja, o review deve ser sobre entrega, estado do produto, contato com o suporte, etc. \n",
    "- Direcionável: para o target \"direcionável\" (\"D\") foram considerados comentários relativos à editora, como qualidade do material do livro, preço do livro e do e-book, tradução e edição. \n",
    "- Não Acionáveis: por fim, os não acionáveis (\"NA\") eram comentários relativos ao autor, ao apreço pelo conteúdo do livro, ou comentários irrelavantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar uma função que transforma as frases da planilha em um texto só \n",
    "    #(Será útil para criar o dicionário com as palavras)\n",
    "def transforma_em_string(coluna):\n",
    "    texto = ''\n",
    "    for linha in coluna:\n",
    "        texto += linha + ' '\n",
    "    return texto    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar uma função que limpa todas as pontuações\n",
    "def cleanup(text):\n",
    "    punctuation = r'[´\"!-.:?;$,/~^_=+*&¨%$#@|\\{}()[\\]]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma função que limpa os espaços duplicados\n",
    "def limpa_espaco(text):\n",
    "    punctuation = r'[\\n]'  # Adicione os caracteres desejados aqui\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma função para remover emoji\n",
    "def remove_emoji(text):\n",
    "    text_without_emojis = unidecode(text)\n",
    "    return text_without_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a função de stopwords\n",
    "def stopwords(texto):\n",
    "    palavras = word_tokenize(texto, language='portuguese') # Tokenize é analisar palavras individualmente, basicamente\n",
    "    palavras_sem_stopword = []\n",
    "    for palavra in palavras:\n",
    "        if palavra not in stopwordsdic:\n",
    "            palavras_sem_stopword.append(palavra)\n",
    "    # Reúna as palavras sem stopwords em uma string novamente\n",
    "    texto_sem_stopword = ' '.join(palavras_sem_stopword)\n",
    "    return texto_sem_stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cria uma função que reúna as funções de limpeza\n",
    "def limpa_tudo(mensagem):\n",
    "    #Aplicando a função de limpeza de pontuação\n",
    "    texto = cleanup(mensagem)\n",
    "    #Deixando tudo em letra minúscula\n",
    "    texto = texto.lower()\n",
    "    #Removendo emoji\n",
    "    texto = remove_emoji(texto)\n",
    "    #Aplicando a função de limpeza de espaço\n",
    "    texto = limpa_espaco(texto)\n",
    "    #Removendo stopwords\n",
    "    texto = stopwords(texto)\n",
    "    #Realiza lemmatização\n",
    "    \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma função que adicione as mensagens limpas à planilha\n",
    "def mensagem_limpa(planilha):   #recebe a planilha e retorna com a coluna de mensagem limpa\n",
    "    planilha['Mensagem Limpa'] = [limpa_tudo(x) for x in list(planilha['Mensagem'])]\n",
    "    return planilha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #separando cada palavra\n",
    "    #texto = texto.split()\n",
    "    #set para tirar repetição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria dicionário de tudo\n",
    "def cria_dicionario(mensagem):\n",
    "    lista_palavras = transforma_em_string(mensagem)\n",
    "    lista_palavras = limpa_tudo(lista_palavras)\n",
    "    lista_palavras = lista_palavras.split()\n",
    "    return lista_palavras  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma função que guarda as palavras em pd.Series\n",
    "def cria_pdseries(lista):\n",
    "    tabela = pd.Series(lista)\n",
    "    return tabela\n",
    "\n",
    "#Cria uma função que retorna a frequência absoluta de cada palavra no texto\n",
    "def freq_abs(tabela):\n",
    "    absoluta = tabela.value_counts()\n",
    "    return absoluta\n",
    "\n",
    "#Cria uma função que retorna a frequência relativa de cada palavra no texto\n",
    "def freq_rel(tabela):\n",
    "    relativa = tabela.value_counts(True)\n",
    "    return relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resolvido',\n",
       " 'grafico',\n",
       " 'elogiam',\n",
       " 'deixou',\n",
       " 'infaliveis',\n",
       " 'cultural',\n",
       " 'obrigado',\n",
       " 'elementos',\n",
       " 'continuacaracterizase',\n",
       " 'american',\n",
       " 'faltantes',\n",
       " 'jornalistas',\n",
       " 'frase',\n",
       " 'diversas',\n",
       " 'surreal',\n",
       " 'complica',\n",
       " 'melhorar',\n",
       " 'faltam',\n",
       " 'tecnicas',\n",
       " 'odio',\n",
       " 'tirar',\n",
       " 'hitler',\n",
       " 'quica',\n",
       " 'sugeria',\n",
       " 'mencionada',\n",
       " 'nunes',\n",
       " 'concentra',\n",
       " 'levantar',\n",
       " 'danificados',\n",
       " 'casar',\n",
       " 'descobrem',\n",
       " 'lastima',\n",
       " 'suporte',\n",
       " 'escritora',\n",
       " 'populares',\n",
       " 'consumo',\n",
       " 'influenciaveis',\n",
       " 'corrija',\n",
       " 'tempo',\n",
       " 'creditado',\n",
       " 'incapacidade',\n",
       " 'mesmos',\n",
       " 'falar',\n",
       " 'best',\n",
       " 'sintoma',\n",
       " 'relacionamento',\n",
       " 'verdadeiramente',\n",
       " 'perderam',\n",
       " 'extremamente',\n",
       " 'exagerado',\n",
       " 'tente',\n",
       " 'wil',\n",
       " 'insights',\n",
       " 'inteiras',\n",
       " 'extrair',\n",
       " 'economias',\n",
       " 'bonitinho',\n",
       " 'responsabilidade',\n",
       " 'induzem',\n",
       " 'apenas',\n",
       " 'correspondente',\n",
       " 'universidades',\n",
       " 'rasgado',\n",
       " 'fico',\n",
       " 'desconexas',\n",
       " 'construiu',\n",
       " 'arrasta',\n",
       " 'descuidada',\n",
       " 'possessivo',\n",
       " 'postaria',\n",
       " 'destes',\n",
       " 'fiscal',\n",
       " 'transformou',\n",
       " 'totalmente',\n",
       " 'producentes',\n",
       " 'janeiro',\n",
       " 'todas',\n",
       " 'sido',\n",
       " 'travada',\n",
       " 'concerteza',\n",
       " 'formato',\n",
       " 'criaram',\n",
       " 'principalmente',\n",
       " 'dentro',\n",
       " 'sensualidade',\n",
       " 'sala',\n",
       " 'tudo',\n",
       " '6',\n",
       " 'enroladoum',\n",
       " 'america',\n",
       " 'chatisse',\n",
       " 'dobradas',\n",
       " 'restringira',\n",
       " 'comecei',\n",
       " 'ler',\n",
       " 'sexo',\n",
       " 'tristeza',\n",
       " 'cima',\n",
       " '256',\n",
       " 'ha',\n",
       " 'qualificados',\n",
       " 'poetica',\n",
       " 'livreto',\n",
       " 'viagens',\n",
       " 'cegas',\n",
       " 'cenarios',\n",
       " 'choque',\n",
       " 'pudor',\n",
       " 'pobre',\n",
       " 'maturidade',\n",
       " 'nacionais',\n",
       " 'explosao',\n",
       " 'acabado',\n",
       " 'correto',\n",
       " 'publicas',\n",
       " 'empoderamento',\n",
       " 'avaliar',\n",
       " 'vitimismos',\n",
       " 'decidir',\n",
       " 'regresso',\n",
       " 'retirada',\n",
       " 'veem',\n",
       " 'hugo',\n",
       " 'mocinho',\n",
       " 'inviavel',\n",
       " 'arrasou',\n",
       " 'acesso',\n",
       " 'devidamente',\n",
       " 'jose',\n",
       " 'paul',\n",
       " 'engana',\n",
       " 'trabalham',\n",
       " 'serias',\n",
       " 'simplistas',\n",
       " 'acucar',\n",
       " 'corri',\n",
       " 'rasgo',\n",
       " 'alguempassou',\n",
       " 'achava',\n",
       " 'intangivel',\n",
       " 'filmes',\n",
       " 'propaga',\n",
       " 'livrarias',\n",
       " 'dramalhao',\n",
       " 'academicas',\n",
       " 'primeira',\n",
       " 'envolve',\n",
       " 'trajetoria',\n",
       " 'branco',\n",
       " '0',\n",
       " 'xxi',\n",
       " 'celular',\n",
       " 'ignaros',\n",
       " 'surrado',\n",
       " 'tentarei',\n",
       " 'precisou',\n",
       " 'green',\n",
       " 'ricas',\n",
       " 'margens',\n",
       " 'apos',\n",
       " 'notado',\n",
       " 'industria',\n",
       " 'extrapole',\n",
       " 'observei',\n",
       " 'estao',\n",
       " 'bonito',\n",
       " 'correlatos',\n",
       " 'imbecil',\n",
       " 'casado',\n",
       " 'iriam',\n",
       " 'crises',\n",
       " 'homero',\n",
       " 'guerra',\n",
       " 'ato',\n",
       " 'livrar',\n",
       " 'produto',\n",
       " 'internet',\n",
       " 'decepcionantese',\n",
       " 'r20',\n",
       " 'valeriam',\n",
       " 'legal',\n",
       " 'comemorativa',\n",
       " 'pensa',\n",
       " 'inicial',\n",
       " 'familia',\n",
       " 'petroleo',\n",
       " 'historico',\n",
       " 'comporta',\n",
       " 'cientificae',\n",
       " 'maria',\n",
       " 'aconteca',\n",
       " 'prevista',\n",
       " 'proposta',\n",
       " 'desconto',\n",
       " 'tira',\n",
       " 'excessivasisso',\n",
       " 'impressos',\n",
       " 'alemao',\n",
       " 'acertar',\n",
       " 'influenciar',\n",
       " 'curiosodade',\n",
       " 'clafin',\n",
       " 'ilustracoes',\n",
       " 'torturar',\n",
       " 'coisas',\n",
       " 'pratico',\n",
       " 'escora',\n",
       " 'r2080',\n",
       " 'poco',\n",
       " 'pode',\n",
       " 'caminhoneiros',\n",
       " 'autoajuda',\n",
       " 'liberal',\n",
       " 'conservador',\n",
       " 'deveria',\n",
       " 'imaginar',\n",
       " 'inumeras',\n",
       " 'reclamou',\n",
       " 'dezenas',\n",
       " 'embotar',\n",
       " 'suportamos',\n",
       " 'acostumado',\n",
       " 'associacoes',\n",
       " 'entregues',\n",
       " 'captado',\n",
       " 'boca',\n",
       " 'desistir',\n",
       " 'desenrolar',\n",
       " 'proposto',\n",
       " 'escolhi',\n",
       " 'reais',\n",
       " 'citacao',\n",
       " 'proveitosa',\n",
       " 'manipula',\n",
       " 'longo',\n",
       " 'sozinho',\n",
       " 'ricos',\n",
       " 'epilogo',\n",
       " 'youtuber',\n",
       " 'pessoais',\n",
       " 'eleito',\n",
       " 'olhar',\n",
       " 'conseguiu',\n",
       " 'minimo',\n",
       " 'interessada',\n",
       " 'perguntando',\n",
       " '1929',\n",
       " 'apto',\n",
       " 'way',\n",
       " 'ninfomaniaca',\n",
       " 'caminhoes',\n",
       " 'justamente',\n",
       " 'claras',\n",
       " 'arabes',\n",
       " 'ninguem',\n",
       " 'acaba',\n",
       " 'maluca',\n",
       " 'apaixonadaesse',\n",
       " 'fraquissimo',\n",
       " 'manson',\n",
       " 'relacao',\n",
       " 'simultaneos',\n",
       " 'comentou',\n",
       " 'alerta',\n",
       " 'r2100',\n",
       " 'conhecimento',\n",
       " 'isaacson',\n",
       " 'contradiz',\n",
       " 'resistente',\n",
       " 'enviado',\n",
       " 'desenvolvido',\n",
       " 'aventura',\n",
       " 'subestima',\n",
       " 'liberdade',\n",
       " 'relatos',\n",
       " 'x',\n",
       " 'genial',\n",
       " 'discurso',\n",
       " 'li',\n",
       " 'expressar',\n",
       " 'presenteei',\n",
       " 'fez',\n",
       " 'trepa',\n",
       " 'alcoolatra',\n",
       " 'cenario',\n",
       " 'fazendo',\n",
       " 'cis',\n",
       " 'proximas',\n",
       " 'orientais',\n",
       " 'categoria',\n",
       " 'protagonistas',\n",
       " 'estudamos',\n",
       " 'energia',\n",
       " 'comportamentos',\n",
       " 'violento',\n",
       " 'apaixonar',\n",
       " 'encontrou',\n",
       " 'riqueza',\n",
       " 'distorcoes',\n",
       " 'queira',\n",
       " 'historias',\n",
       " 'generalizacoes',\n",
       " 'fatos',\n",
       " 'ultimo',\n",
       " 'is',\n",
       " 'citaria',\n",
       " 'argumentam',\n",
       " 'busquei',\n",
       " 'fugiu',\n",
       " 'boas',\n",
       " 'menina',\n",
       " 'interessado',\n",
       " 'inves',\n",
       " 'sutil',\n",
       " 'amazon',\n",
       " 'hill',\n",
       " 'milagre',\n",
       " 'chorar',\n",
       " 'esquerda',\n",
       " 'infrutifera',\n",
       " 'tratava',\n",
       " 'inteirinho',\n",
       " 'apertamento',\n",
       " 'traduzido',\n",
       " 'posicionando',\n",
       " 'inscritos',\n",
       " 'oh',\n",
       " 'cheguei',\n",
       " 'chata',\n",
       " 'gasto',\n",
       " 'requer',\n",
       " 'all',\n",
       " 'alinhado',\n",
       " 'novela',\n",
       " 'ai',\n",
       " 'relacionar',\n",
       " 'assassino',\n",
       " 'brilhante',\n",
       " 'desconhecimento',\n",
       " 'prestar',\n",
       " 'abusivo',\n",
       " 'tornase',\n",
       " 'interesse',\n",
       " 'divulgala',\n",
       " 'adultos',\n",
       " 'ocupando',\n",
       " 'nova',\n",
       " 'desperdicio',\n",
       " 'redeas',\n",
       " 'irritada',\n",
       " 'danificadas',\n",
       " 'repetitivos',\n",
       " 'banal',\n",
       " 'brasil',\n",
       " 'excita',\n",
       " 'rocco',\n",
       " 'total',\n",
       " 'pacote',\n",
       " 'mimada',\n",
       " 'precisando',\n",
       " '50',\n",
       " 'ia',\n",
       " 'barbaridades',\n",
       " 'tobias',\n",
       " 'ingenuos',\n",
       " 'recebido',\n",
       " 'impressas',\n",
       " 'necessario',\n",
       " 'estreita',\n",
       " 'marido',\n",
       " 'achei',\n",
       " 'maximo',\n",
       " 'praticidade',\n",
       " 'movimentos',\n",
       " 'alegase',\n",
       " 'impresso',\n",
       " 'reparem',\n",
       " 'coachingexistem',\n",
       " 'concerne',\n",
       " 'desisti',\n",
       " 'esquecendo',\n",
       " '576',\n",
       " 'grupo',\n",
       " 'monumental',\n",
       " 'calice',\n",
       " 'paiela',\n",
       " 'culpados',\n",
       " 'dizem',\n",
       " 'excepcionalmente',\n",
       " 'resumindoler',\n",
       " 'votos',\n",
       " 'compadrios',\n",
       " 'biblicas',\n",
       " 'abandonar',\n",
       " 'contato',\n",
       " 'sustentou',\n",
       " 'breve',\n",
       " 'christian',\n",
       " 'parecidos',\n",
       " 'editados',\n",
       " 'culpa',\n",
       " 'reboque',\n",
       " 'radicais',\n",
       " 'demora',\n",
       " 'nene',\n",
       " 'suplantado',\n",
       " 'resumido',\n",
       " 'enxugando',\n",
       " 'aspas',\n",
       " 'apontada',\n",
       " 'machista',\n",
       " 'machistae',\n",
       " 'humano',\n",
       " '2015',\n",
       " 'desconstrucao',\n",
       " 'golpe',\n",
       " 'cair',\n",
       " 'pensamos',\n",
       " 'indicar',\n",
       " 'serve',\n",
       " 'cheio',\n",
       " 'pedacos',\n",
       " 'charlatanismo',\n",
       " 'unico',\n",
       " 'estilo',\n",
       " 'zelo',\n",
       " 'todo',\n",
       " 'garoto',\n",
       " 'ridicula',\n",
       " 'oferecidas',\n",
       " 'decente',\n",
       " 'viva',\n",
       " 'centenaria',\n",
       " 'casadas',\n",
       " 'marco',\n",
       " 'caminho',\n",
       " 'profunda',\n",
       " 'tranquilidade',\n",
       " 'nomes',\n",
       " 'martin',\n",
       " 'versoes',\n",
       " 'chavez',\n",
       " 'midias',\n",
       " '1511',\n",
       " 'conviver',\n",
       " '1964',\n",
       " 'aprecia',\n",
       " 'jesus',\n",
       " 'fundamento',\n",
       " 'andamento',\n",
       " 'vc',\n",
       " 'forcas',\n",
       " 'horror',\n",
       " 'esquerdista',\n",
       " 'textos',\n",
       " 'cm',\n",
       " 'seculo',\n",
       " 'autopromocao',\n",
       " 'lata',\n",
       " 'esperar',\n",
       " 'status',\n",
       " 'substituir',\n",
       " 'teresa',\n",
       " 'compreendido',\n",
       " 'epicos',\n",
       " 'horrivelmente',\n",
       " 'votar',\n",
       " 'parcel',\n",
       " 'obsessivas',\n",
       " 'cobrado',\n",
       " 'sair',\n",
       " 'novembro',\n",
       " 'sac',\n",
       " 'prova',\n",
       " 'leya',\n",
       " 'quanta',\n",
       " 'trocaloja',\n",
       " 'macante',\n",
       " 'dimensoes',\n",
       " 'florestas',\n",
       " 'prontamente',\n",
       " 'entreguei',\n",
       " 'demoniaco',\n",
       " 'minuciosa',\n",
       " 'spoiler',\n",
       " 'evitado',\n",
       " 'nivel',\n",
       " 'opcao',\n",
       " 'aborto',\n",
       " 'espacamento',\n",
       " 'praxe',\n",
       " 'minima',\n",
       " 'corinne',\n",
       " 'adultespecialmente',\n",
       " 'papel',\n",
       " 'tonta',\n",
       " 'milhares',\n",
       " 'virtual',\n",
       " 'mudou',\n",
       " 'historicamente',\n",
       " 'porco',\n",
       " 'ghosts',\n",
       " '2019',\n",
       " 'escolha',\n",
       " 'leonardo',\n",
       " 'agrade',\n",
       " 'sera',\n",
       " 'cabem',\n",
       " 'estragar',\n",
       " 'prosaica',\n",
       " 'fase',\n",
       " 'romance',\n",
       " 'fortaleceram',\n",
       " 'instrucao',\n",
       " 'amei',\n",
       " 'novidade',\n",
       " 'entendimento',\n",
       " 'comercializacao',\n",
       " 'virtude',\n",
       " 'so',\n",
       " 'determinado',\n",
       " 'entretanto',\n",
       " 'esforco',\n",
       " 'harvard',\n",
       " 'explorando',\n",
       " 'concisa',\n",
       " 'analisei',\n",
       " '1917',\n",
       " 'feminista',\n",
       " 'idioma',\n",
       " 'vei',\n",
       " 'insatisfeita',\n",
       " 'avalio',\n",
       " 'daquele',\n",
       " 'pesssimo',\n",
       " 'encontraram',\n",
       " 'voce',\n",
       " 'cansativas',\n",
       " 'assiduos',\n",
       " 'to',\n",
       " 'doutrinacao',\n",
       " 'externa',\n",
       " 'retirado',\n",
       " 'basicamente',\n",
       " 'academia',\n",
       " 'principes',\n",
       " 'mancha',\n",
       " 'prolixa',\n",
       " 'comprovei',\n",
       " 'processo',\n",
       " 'respondem',\n",
       " 'semanas',\n",
       " 'vitimiza',\n",
       " 'humor',\n",
       " 'trai',\n",
       " 'consagrado',\n",
       " 'costuma',\n",
       " 'habito',\n",
       " 'fotomas',\n",
       " 'ocorrido',\n",
       " 'ter',\n",
       " 'ridiculo',\n",
       " 'gostaram',\n",
       " 'detestavel',\n",
       " 'secreta',\n",
       " 'quadro',\n",
       " 'regra',\n",
       " 'pesada',\n",
       " 'prendem',\n",
       " 'madre',\n",
       " 'reiterando',\n",
       " 'the',\n",
       " 'opcoes',\n",
       " 'recebi',\n",
       " 'sequestrou',\n",
       " 'bocuda',\n",
       " 'significados',\n",
       " 'especial',\n",
       " 'estrelas',\n",
       " 'afirmacoes',\n",
       " 'motivacional',\n",
       " 'interessar',\n",
       " 'atento',\n",
       " 'metrica',\n",
       " 'conter',\n",
       " 'possuir',\n",
       " 'aprender',\n",
       " 'leigo',\n",
       " 'autoritarios',\n",
       " 'terceira',\n",
       " 'computador',\n",
       " 'imagens',\n",
       " 'rasgos',\n",
       " 'interacoes',\n",
       " 'pensam',\n",
       " 'lembra',\n",
       " 'sofredora',\n",
       " 'trechos',\n",
       " 'escreve',\n",
       " 'desconhecidas',\n",
       " 'extraviado',\n",
       " 'historiador',\n",
       " 'completa',\n",
       " 'absolutas',\n",
       " 'possamos',\n",
       " 'anseio',\n",
       " 'acabam',\n",
       " 'jornal',\n",
       " 'geralmente',\n",
       " 'confortavel',\n",
       " 'compram',\n",
       " 'dou',\n",
       " 'justificasse',\n",
       " 'sensivel',\n",
       " '15',\n",
       " 'resenhas',\n",
       " 'oficial',\n",
       " 'eleicoesouviraoperderam',\n",
       " 'writers',\n",
       " 'pinca',\n",
       " 'leituraresumindo',\n",
       " 'topo',\n",
       " 'escritores',\n",
       " 'ressaltar',\n",
       " 'dito',\n",
       " 'ocorrea',\n",
       " 'referencia',\n",
       " 'criticalo',\n",
       " 'finas',\n",
       " 'disponibilizado',\n",
       " 'latina',\n",
       " 'realista',\n",
       " 'trazem',\n",
       " 'ajuda',\n",
       " 'empregas',\n",
       " 'querer',\n",
       " 'otimos',\n",
       " 'acrescimo',\n",
       " 'lanca',\n",
       " 'impedir',\n",
       " 'alteracao',\n",
       " 'diante',\n",
       " 'detalhe',\n",
       " 'amor',\n",
       " 'ressalvas',\n",
       " 'paraguai',\n",
       " 'contestar',\n",
       " 'leonprincipe',\n",
       " 'baixo',\n",
       " 'esteticamente',\n",
       " '28122017',\n",
       " 'texto',\n",
       " 'virgem',\n",
       " 'ilegivel',\n",
       " 'lei',\n",
       " 'conferir',\n",
       " 'profundidade',\n",
       " 'chamada',\n",
       " 'ptismolulismocomunismo',\n",
       " 'agradar',\n",
       " 'lenda',\n",
       " 'ajudaram',\n",
       " 'exageradamente',\n",
       " 'investir',\n",
       " 'favor',\n",
       " 'svetlana',\n",
       " 'casa',\n",
       " 'negativas',\n",
       " 'havido',\n",
       " 'inclusive',\n",
       " 'raiva',\n",
       " 'avisando',\n",
       " 'apena',\n",
       " 'dano',\n",
       " 'taxado',\n",
       " 'ee',\n",
       " 'ficasse',\n",
       " 'desses',\n",
       " 'indelicado',\n",
       " 'compreender',\n",
       " 'sensacao',\n",
       " 'jus',\n",
       " 'aventureiros',\n",
       " 'mesma',\n",
       " 'inumeros',\n",
       " 'sabemos',\n",
       " 'namoradinhos',\n",
       " 'estupros',\n",
       " 'indecisoes',\n",
       " 'promessa',\n",
       " 'foto',\n",
       " 'httpwwwamazoncombrgamethronessongfireebookdpb000qcs8twrefpdsimsbskinc6',\n",
       " 'anedotas',\n",
       " 'sucesso',\n",
       " 'proprios',\n",
       " 'nelepessoas',\n",
       " 'itatiaia',\n",
       " 'util',\n",
       " 'obs',\n",
       " 'estuproao',\n",
       " 'proporcione',\n",
       " 'pocao',\n",
       " 'riscos',\n",
       " 'prol',\n",
       " 'descabida',\n",
       " 'clube',\n",
       " 'andam',\n",
       " 'contei',\n",
       " 'falecido',\n",
       " 'cartas',\n",
       " 'beijo',\n",
       " 'substantivos',\n",
       " 'marca',\n",
       " 'recentemente',\n",
       " 'concordo',\n",
       " 'mencionadas',\n",
       " 'ex',\n",
       " 'principios',\n",
       " 'proposital',\n",
       " 'tedio',\n",
       " 'cuidadosa',\n",
       " 'apelo',\n",
       " 'autobiografia',\n",
       " 'medida',\n",
       " 'perspectiva',\n",
       " 'pouco',\n",
       " 'momento',\n",
       " 'nenhuma',\n",
       " 'preciso',\n",
       " 'agressiva',\n",
       " '2outros',\n",
       " 'corrigir',\n",
       " 'olho',\n",
       " 'apaixonaessa',\n",
       " 'historicas',\n",
       " 'contemporaneo',\n",
       " 'incorporar',\n",
       " 'nesses',\n",
       " 'encher',\n",
       " 'cabelo',\n",
       " '3',\n",
       " 'importantes',\n",
       " 'submarino',\n",
       " 'respondendo',\n",
       " 'desvelar',\n",
       " 'volta',\n",
       " 'expostas',\n",
       " 'polen',\n",
       " 'exercicio',\n",
       " 'encontraria',\n",
       " 'acidentes',\n",
       " 'rebuscada',\n",
       " 'schwarcz',\n",
       " 'curtir',\n",
       " 'iniciando',\n",
       " 'fraudulento',\n",
       " 'dominantes',\n",
       " 'usualmente',\n",
       " 'inicia',\n",
       " 'soar',\n",
       " 'direcionava',\n",
       " 'bufo',\n",
       " 'avanco',\n",
       " 'explicacao',\n",
       " 'establish',\n",
       " 'conclui',\n",
       " 'acoes',\n",
       " 'orgulho',\n",
       " 'lembram',\n",
       " 'autorizo',\n",
       " \"sant'anna\",\n",
       " 'tentar',\n",
       " 'noticia',\n",
       " 'novamente',\n",
       " 'deseja',\n",
       " 'marcadas',\n",
       " 'superior',\n",
       " 'defesa',\n",
       " 'relacionamentos',\n",
       " 'repete',\n",
       " 'classe',\n",
       " 'importa',\n",
       " 'operadores',\n",
       " 'destaque',\n",
       " 'abuso',\n",
       " 'irrisorios',\n",
       " 'completo',\n",
       " '577',\n",
       " 'vazias',\n",
       " 'misturando',\n",
       " 'similar',\n",
       " 'boletos',\n",
       " 'sofrimento',\n",
       " 'vista',\n",
       " 'enfase',\n",
       " 'encantamento',\n",
       " 'males',\n",
       " 'funcional',\n",
       " 'misse',\n",
       " 'blogs',\n",
       " 'povos',\n",
       " 'conteudo',\n",
       " 'sugerindo',\n",
       " 'potter',\n",
       " 'sinto',\n",
       " 'aumentariam',\n",
       " 'chegaram',\n",
       " 'zahar',\n",
       " 'criada',\n",
       " 'pulei',\n",
       " 'cadernos',\n",
       " 'apanhado',\n",
       " 'falando',\n",
       " 'atendimento',\n",
       " 'defender',\n",
       " '1112',\n",
       " 'salvasse',\n",
       " 'compilador',\n",
       " 'lendo',\n",
       " 'estadounidense',\n",
       " 'crime',\n",
       " 'arqueologia',\n",
       " 'citar',\n",
       " 'voltaria',\n",
       " 'razao',\n",
       " 'embusteiro',\n",
       " 'ficado',\n",
       " 'intediante',\n",
       " 'ora',\n",
       " 'sugiro',\n",
       " 'gastam',\n",
       " 'recomendo',\n",
       " 'incompleto',\n",
       " 'afixada',\n",
       " 'painao',\n",
       " 'cary',\n",
       " 'dizia',\n",
       " 'personalidades',\n",
       " 'impressionar',\n",
       " 'vinganca',\n",
       " 'formam',\n",
       " 'palestras',\n",
       " 'disforme',\n",
       " 'queputz',\n",
       " 'entrada',\n",
       " 'costumo',\n",
       " 'cosmos',\n",
       " 'resultado',\n",
       " 'idade',\n",
       " 'felizmente',\n",
       " 'costurado',\n",
       " 'questao',\n",
       " 'vergonhoso',\n",
       " 'ali',\n",
       " 'futilidade',\n",
       " 'compensa',\n",
       " 'distopia',\n",
       " 'enganacao',\n",
       " 'perfil',\n",
       " 'recemsaido',\n",
       " 'forma',\n",
       " 'embasamento',\n",
       " 'grandes',\n",
       " 'etc',\n",
       " 'queria',\n",
       " 'frente',\n",
       " 'eou',\n",
       " 'propoe',\n",
       " 'serao',\n",
       " 'descreve',\n",
       " 'kamal',\n",
       " 'fronteira',\n",
       " 'contratam',\n",
       " 'pesquisares',\n",
       " 'costas',\n",
       " 'infantis',\n",
       " 'paciencia',\n",
       " 'pdf',\n",
       " 'encheu',\n",
       " 'trouxe',\n",
       " 'beleza',\n",
       " 'potencialque',\n",
       " 'mensagem',\n",
       " 'melhoram',\n",
       " 'decisao',\n",
       " 'ideal',\n",
       " 'feridos',\n",
       " 'diagramado',\n",
       " 'alberto',\n",
       " 'devolvendo',\n",
       " 'feitas',\n",
       " 'reclamarem',\n",
       " 'passaram',\n",
       " 'like',\n",
       " 'dai',\n",
       " 'comparando',\n",
       " 'adequada',\n",
       " \"'coisa\",\n",
       " 'terminava',\n",
       " 'novo',\n",
       " 'publicado',\n",
       " 'complain',\n",
       " 'fraude',\n",
       " 'estreitas',\n",
       " 'autores',\n",
       " 'liegoistairritantecheio',\n",
       " 'permite',\n",
       " 'acessibilidade',\n",
       " 'alias',\n",
       " 'graca',\n",
       " 'progresso',\n",
       " 'informando',\n",
       " 'monica',\n",
       " 'ditador',\n",
       " 'posicao',\n",
       " 'reacao',\n",
       " 'cartilha',\n",
       " 'humanidade',\n",
       " 'estimular',\n",
       " 'fator',\n",
       " 'presidente',\n",
       " 'envolvia',\n",
       " 'arrasa',\n",
       " 'guia',\n",
       " 'jornalista',\n",
       " 'finalizar',\n",
       " 'apelos',\n",
       " 'sucinto',\n",
       " 'capitaliza',\n",
       " 'vasto',\n",
       " 'principais',\n",
       " 'banalizacao',\n",
       " 'deus',\n",
       " 'idilico',\n",
       " 'shinyashiki',\n",
       " 'perder',\n",
       " 'vitimizacao',\n",
       " 'tal',\n",
       " 'desinteressante',\n",
       " 'jogada',\n",
       " 'crimes',\n",
       " 'amzon',\n",
       " 'hominideo',\n",
       " 'particularmente',\n",
       " 'usando',\n",
       " 'reembolsam',\n",
       " 'estudioso',\n",
       " 'corrigido',\n",
       " 'radical',\n",
       " 'francamente',\n",
       " 'reportado',\n",
       " 'deturpa',\n",
       " 'satisfatorios',\n",
       " 'apresentadas',\n",
       " 'aceitem',\n",
       " 'instaveis',\n",
       " 'rota',\n",
       " 'modo',\n",
       " 'avaliacoes',\n",
       " 'fina',\n",
       " 'proposicoes',\n",
       " 'porta',\n",
       " 'absurdo',\n",
       " 'paragrafos',\n",
       " 'hbo',\n",
       " 'chatas',\n",
       " 'procurado',\n",
       " 'cara',\n",
       " 'acompanha',\n",
       " 'marcantes',\n",
       " 'aprendem',\n",
       " 'boba',\n",
       " 'sentem',\n",
       " 'obivias',\n",
       " 'fundo',\n",
       " 'atrapalhe',\n",
       " 'marketing',\n",
       " 'fobia',\n",
       " 'brancos',\n",
       " 'grito',\n",
       " 'iniciantes',\n",
       " 'fique',\n",
       " 'escolares',\n",
       " 'novelesco',\n",
       " 'centenas',\n",
       " 'miraclemorning',\n",
       " 'arrastada',\n",
       " 'jeito',\n",
       " 'obter',\n",
       " 'filosofica',\n",
       " 'gostinho',\n",
       " 'qtd',\n",
       " 'assunto',\n",
       " 'estarei',\n",
       " 'entediante',\n",
       " 'madalena',\n",
       " 'exagerada',\n",
       " 'produtivas',\n",
       " 'pula',\n",
       " 'superacao',\n",
       " ...}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Vou criar o dicionário de todas as palavras e contabilizar\n",
    "\n",
    "vocabulario = cria_vocula(train.Mensagem)  #retornos uma lista com todas as palavras\n",
    "dicionario = set(dicionario)  #retira as palavras repetidas\n",
    "dicionario\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a probabilidade de todas as palavras estarem contidas num texto não é a mesma? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
