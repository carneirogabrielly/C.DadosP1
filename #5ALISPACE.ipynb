{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Alison Araujo\n",
    "\n",
    "Nome: Gabrielly Carneiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aliso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aliso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading word_tokenize: Package 'word_tokenize' not\n",
      "[nltk_data]     found in index\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('word_tokenize')\n",
    "stopwordsdic = stopwords.words('portuguese')\n",
    "\n",
    "from spacy import load\n",
    "nlp = load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print('Esperamos trabalhar no diretório')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('dados_treino.xlsx')\n",
    "# train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('dados_teste.xlsx')\n",
    "# test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na primeira etapa, de classificação manual, consideramos três targets para os reviews: Acionável, Direcionável e Não Acionável. \n",
    "\n",
    "- Acionável: para ser considerado \"acionável\" (\"A\") o review deve ser passível de alguma ação pela Amazon, ou seja, o review deve ser sobre entrega, estado do produto, contato com o suporte, etc. \n",
    "- Direcionável: para o target \"direcionável\" (\"D\") foram considerados comentários relativos à editora, como qualidade do material do livro, preço do livro e do e-book, tradução e edição. \n",
    "- Não Acionáveis: por fim, os não acionáveis (\"NA\") eram comentários relativos ao autor, ao apreço pelo conteúdo do livro, ou comentários irrelavantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções úteis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar uma função que transforma as frases da planilha em um texto só \n",
    "    #(Será útil para criar o dicionário com as palavras)\n",
    "\n",
    "def transforma_em_string(coluna):\n",
    "    texto = ''\n",
    "    for linha in coluna:\n",
    "        texto += linha + ' '\n",
    "    return texto    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar uma função que limpa todas as pontuações\n",
    "#recebe um texto\n",
    "#vou utilizar ela na função limpa tudo\n",
    "def cleanup(text):\n",
    "    punctuation = r'[´\"\\'!-.:?;$,/~^_=+*&¨%$#@|\\{}()[\\]]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma função que limpa os espaços duplicados\n",
    "#vou utilizar ela na função limpa tudo\n",
    "def limpa_espaco(text):\n",
    "    punctuation = r'[\\n]'  # Adicione os caracteres desejados aqui\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma função para remover emoji\n",
    "#vou utilizar ela na função limpa tudo\n",
    "def remove_emoji(text):\n",
    "    text_without_emojis = unidecode(text)\n",
    "    return text_without_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a função de stopwords\n",
    "#vou utilizar ela na função limpa tudo\n",
    "#vai receber o texto limpo pelas outras funções\n",
    "def stopwords(texto):\n",
    "    palavras = word_tokenize(texto, language='portuguese') # Tokenize é analisar palavras individualmente, basicamente\n",
    "    palavras_sem_stopword = []\n",
    "    for palavra in palavras:\n",
    "        if palavra not in stopwordsdic:\n",
    "            palavras_sem_stopword.append(palavra)\n",
    "    # Reúna as palavras sem stopwords em uma string novamente\n",
    "    texto_sem_stopword = ' '.join(palavras_sem_stopword)\n",
    "    return texto_sem_stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a função de lematização\n",
    "#vou utilizar ela na função limpa tudo\n",
    "#vai receber o texto limpo pelas outras funções, incluindo limpeza de stopwords\n",
    "\n",
    "def lemmat(texto):\n",
    "    doc = nlp(texto)\n",
    "    lemmat_radicais = []\n",
    "    for radicais in doc:\n",
    "        lemmat_radicais.append(radicais.lemma_)\n",
    "    texto_lemmat = ' '.join(lemmat_radicais)    \n",
    "    return texto_lemmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cria uma função que reúna as funções de limpeza\n",
    "def limpa_tudo(mensagem):\n",
    "    texto = cleanup(mensagem) #Aplicando a função de limpeza de pontuação\n",
    "    texto = texto.lower() #Deixando tudo em letra minúscula\n",
    "    texto = remove_emoji(texto) #Removendo emoji\n",
    "    texto = limpa_espaco(texto) #Aplicando a função de limpeza de espaços\n",
    "    texto = stopwords(texto) #Removendo stopwords\n",
    "    texto = lemmat(texto) #Realiza lemmatização\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma função que limpa as linhas da planilha e adiciona uma coluna com as mensagens limpas à planilha\n",
    "def mensagem_limpa(planilha):   #recebe a planilha e cria uma nova planilha com a coluna de mensagem limpa com as frases limpas\n",
    "    planilha_limpa = planilha.copy()\n",
    "    planilha_limpa['Mensagem Limpa'] = [limpa_tudo(x) for x in list(planilha['Mensagem'])]\n",
    "    return planilha_limpa    #retorna a planilha modificada\n",
    "\n",
    "planilha_treino_limpa = mensagem_limpa(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria função que cria o vocabulário de tudo\n",
    "def cria_vocabulario(coluna_mensagem_limpa_da_planilha_limpa):                       #recebe uma coluna da planilha\n",
    "    lista_palavras = transforma_em_string(coluna_mensagem_limpa_da_planilha_limpa)\n",
    "    lista_palavras = lista_palavras.split()\n",
    "    return lista_palavras     #devolve uma lista com as palavras separadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria função que retorna uma lista sem as palavras repetidas\n",
    "def remove_repeticao(lista_de_palavras):\n",
    "    dic = set(lista_de_palavras)\n",
    "    lista_vocabulario_sem_repeticao = list(dic)\n",
    "    return lista_vocabulario_sem_repeticao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma função que guarda as palavras em pd.Series e calculas frequencia (relativa e absoluta) das palavras\n",
    "#recebe uma lista (devolvida pelo cria vocabulário, preferencialmente)\n",
    "def cria_pdseries(lista):\n",
    "    tabela = pd.Series(lista)\n",
    "    return tabela\n",
    "\n",
    "#Cria uma função que retorna a frequência absoluta de cada palavra no texto\n",
    "#recebe uma tabela de pd\n",
    "def freq_abs(tabela):\n",
    "    absoluta = tabela.value_counts()\n",
    "    return absoluta\n",
    "\n",
    "#Cria uma função que retorna a frequência relativa de cada palavra no texto\n",
    "def freq_rel(tabela):\n",
    "    relativa = tabela.value_counts(True)\n",
    "    return relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria função de divisão com base nas categorias/targets\n",
    "## Cria uma função que recebe a planilha e o target e \n",
    "# retorna o total de palavras e as tabelas de frequencia absoluta e relativa e o vocabulario sem palavras repetidas, nessa ordem\n",
    "#vou falar que ela recebe a planilha limpa já\n",
    "\n",
    "def divisao_categorias(planilha_limpa, target):\n",
    "    #Etapa de divisão de categorias     \n",
    "    #criou uma nova planilha apenas com as linha com aquele target                \n",
    "    filtro_target = planilha_limpa.loc[planilha_limpa['Acionável/Direcionável/Não Acionável'] == target]\n",
    "    vocab_target = cria_vocabulario(filtro_target[\"Mensagem Limpa\"]) #vocabulario daquele target\n",
    "    df_vocab_target = cria_pdseries(vocab_target)\n",
    "    freq_rel_target = freq_rel(df_vocab_target)\n",
    "    freq_abs_target = freq_abs(df_vocab_target)   #frequencia de palavras daquele target\n",
    "    total_target = freq_abs_target.sum()  #total de palavras daquele target\n",
    "    #criar vocabulario limpo\n",
    "    vocab_target_sr = remove_repeticao(vocab_target)   #vocabulario do target sem palavras repetidas\n",
    "    return total_target, freq_abs_target, freq_rel_target, vocab_target_sr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\\#5ALISPACE.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     vocab_planilha_sr \u001b[39m=\u001b[39m remove_repeticao(vocab_planilha)       \u001b[39m#vocabulario sem repeticao (é uma lista)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m total_planilha, freq_abs_planilha, freq_rel_planilha, vocab_planilha_sr\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X34sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m plan\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plan' is not defined"
     ]
    }
   ],
   "source": [
    "# Função que realiza a divisão de toda a planilha \n",
    "# # Função que recebe a planilha já limpa e retorna:\n",
    "# o total de palavras com repetição [0] (int)\n",
    "# a tabela com a frequência absoluta de cada palavra na planilha [1] (Series)\n",
    "# a tabela com a frequência relativa de cada palavra na planilha [2] (Series)\n",
    "# a lista com todas as palavras da planilha sem repetição [3] (list)\n",
    "def divisao_planilhas(planilha_limpa):\n",
    "    \n",
    "    coluna_limpa = planilha_limpa[\"Mensagem Limpa\"]                   #separa só a coluna \"Mensagem Limpa\"\n",
    "    vocab_planilha = cria_vocabulario(coluna_limpa)             #lista de palavras na coluna \"Mensagem Limpa\"\n",
    "    df_vocab_planilha = cria_pdseries(vocab_planilha)       #coloca essa lista em um df\n",
    "    freq_abs_planilha = freq_abs(df_vocab_planilha)         #calcula a frequência absoluta de cada palavra\n",
    "    freq_rel_planilha = freq_rel(df_vocab_planilha)         #calcula a frequência relativa de cada palavra\n",
    "    total_planilha = freq_abs_planilha.sum()                #calcula o total de palavras com repetição\n",
    "    vocab_planilha_sr = remove_repeticao(vocab_planilha)       #vocabulario sem repeticao (é uma lista)\n",
    "\n",
    "    return total_planilha, freq_abs_planilha, freq_rel_planilha, vocab_planilha_sr\n",
    "\n",
    "plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que cria um dicionário com as palavras e as frequencias absolutas\n",
    "\n",
    "#vou criar um dicionário com todas as palavras e seus valores de \n",
    "# frequencia absoluta para cada target\n",
    "# aí vai ficar mais rapido de encontrar os valores\n",
    "# do que ter que suavizar pra cada palavra toda vez\n",
    "# que chamar o loop\n",
    "def dicionario_prob_palavra_dado_target_treino(planilha_treino_limpa, target):\n",
    "    coluna_limpa = planilha_treino_limpa[\"Mensagem Limpa\"]\n",
    "    dados_target = divisao_categorias(planilha_treino_limpa, target)\n",
    "    # frequencias_relativas = dados_target[2]\n",
    "    frequencias_absolutas = dados_target[1]\n",
    "\n",
    "    dic_treino = {} \n",
    "    \n",
    "    for frase in coluna_limpa:\n",
    "        frase = frase.split()\n",
    "        for palavra in frase:\n",
    "            if palavra not in dic_treino:\n",
    "                if palavra in frequencias_absolutas:\n",
    "                    freq_abs_palavra = frequencias_absolutas[palavra]\n",
    "                    dic_treino[palavra] = freq_abs_palavra\n",
    "    return dic_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que calcula probabidade da frase dado target realizando suavização de LaPlace\n",
    "# Probabilidade da frase dado target mais suavização de LaPlace\n",
    "def frase_dado_target(frase_do_teste, target, planilha_treino_limpa):\n",
    "    prob_frase_dado_classe = 1\n",
    "    frase_do_teste =  frase_do_teste.split()\n",
    "    planilha_limpa = mensagem_limpa(train)\n",
    "    dic_probabilidades_por_classe_treino = dicionario_prob_palavra_dado_target_treino(planilha_limpa, target)   #dicionario com as palavras e suas frequencias absolutas\n",
    "    dados_target = divisao_categorias(planilha_treino_limpa, target)\n",
    "    qtdd_palavras = dados_target[0]                  #quantidade de palavras no target informado\n",
    "    qtdd_palavras_sem_repeticao = len(dados_target[3]) \n",
    "    \n",
    "    alfa = 0.01\n",
    "    for palavra in frase_do_teste:\n",
    "        if palavra in dic_probabilidades_por_classe_treino:\n",
    "            freq_abs_palavra = dic_probabilidades_por_classe_treino[palavra]\n",
    "            #APLIQUEI A SUAVIZAÇÃO DE LA PLACE\n",
    "            prob_palavra_dado_classe = (freq_abs_palavra + alfa)/(qtdd_palavras + alfa*qtdd_palavras_sem_repeticao)\n",
    "            prob_frase_dado_classe *= prob_palavra_dado_classe\n",
    "        else:\n",
    "            freq_abs_palavra = 0\n",
    "            #APLIQUEI A SUAVIZAÇÃO DE LA PLACE\n",
    "            prob_palavra_dado_classe = (freq_abs_palavra + alfa)/(qtdd_palavras + alfa*qtdd_palavras_sem_repeticao)\n",
    "            prob_frase_dado_classe *= prob_palavra_dado_classe\n",
    "    return prob_frase_dado_classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de classificação das frases (quanto a acionável, não acionável e direcionável)\n",
    "#recebe a função já limpa\n",
    "def classificador(frase_do_teste, planilha_treino):\n",
    "    \n",
    "    #Extraindo as informações\n",
    "    total_planilha_N = divisao_categorias(planilha_treino, \"N\")[0]\n",
    "    total_planilha_D = divisao_categorias(planilha_treino, \"D\")[0]\n",
    "    total_planilha_A = divisao_categorias(planilha_treino, \"A\")[0]\n",
    "    total_planilha = divisao_planilhas(planilha_treino)[0]\n",
    "    \n",
    "    #Cálculo das probabilidades\n",
    "    P_frase_dado_A = frase_dado_target(frase_do_teste, \"A\", planilha_treino)\n",
    "    P_frase_dado_D = frase_dado_target(frase_do_teste, \"D\", planilha_treino)\n",
    "    P_frase_dado_N = frase_dado_target(frase_do_teste, \"N\", planilha_treino)\n",
    "    P_N = total_planilha_N/total_planilha         #probabilidade de estar na categoria N\n",
    "    P_D = total_planilha_D/total_planilha         #probabilidade de estar na categoria D\n",
    "    P_A = total_planilha_A/total_planilha         #probabilidade de estar na categoria A\n",
    "    \n",
    "    P_A_dado_frase = P_frase_dado_A*P_A\n",
    "    P_N_dado_frase = P_frase_dado_N*P_N\n",
    "    P_D_dado_frase = P_frase_dado_D*P_D\n",
    "        \n",
    "    #Classificação\n",
    "    if P_A_dado_frase >= P_D_dado_frase and P_A_dado_frase >= P_N_dado_frase:    #na classificação manual quando impatava a prioridade era acionável\n",
    "        return \"A\"\n",
    "    elif P_D_dado_frase > P_N_dado_frase and P_D_dado_frase > P_A_dado_frase:\n",
    "        return \"D\"\n",
    "    elif P_N_dado_frase > P_D_dado_frase and P_N_dado_frase > P_A_dado_frase:\n",
    "        return \"N\"\n",
    "    else:\n",
    "        return \"Houve um impasse\"    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying:   2%|▏         | 6/250 [00:54<36:40,  9.02s/rows]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\\#5ALISPACE.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     planilha_nova[\u001b[39m'\u001b[39m\u001b[39mClassificador Automático\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m resultados\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m planilha_nova\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(classifica_planilha(test, train))\n",
      "\u001b[1;32mc:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\\#5ALISPACE.ipynb Cell 31\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m resultados \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m frase \u001b[39min\u001b[39;00m tqdm(avaliacoes_limpas, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mClassifying\u001b[39m\u001b[39m\"\u001b[39m, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrows\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     resultado \u001b[39m=\u001b[39m classificador(frase, planilha_treino_limpa)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     resultados\u001b[39m.\u001b[39mappend(resultado)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Atribuir a lista de resultados à coluna 'Classificador Automático'\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\\#5ALISPACE.ipynb Cell 31\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#Cálculo das probabilidades\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m P_frase_dado_A \u001b[39m=\u001b[39m frase_dado_target(frase_do_teste, \u001b[39m\"\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\"\u001b[39m, planilha_treino)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m P_frase_dado_D \u001b[39m=\u001b[39m frase_dado_target(frase_do_teste, \u001b[39m\"\u001b[39;49m\u001b[39mD\u001b[39;49m\u001b[39m\"\u001b[39;49m, planilha_treino)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m P_frase_dado_N \u001b[39m=\u001b[39m frase_dado_target(frase_do_teste, \u001b[39m\"\u001b[39m\u001b[39mN\u001b[39m\u001b[39m\"\u001b[39m, planilha_treino)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m P_N \u001b[39m=\u001b[39m total_planilha_N\u001b[39m/\u001b[39mtotal_planilha         \u001b[39m#probabilidade de estar na categoria N\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\\#5ALISPACE.ipynb Cell 31\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m prob_frase_dado_classe \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m frase_do_teste \u001b[39m=\u001b[39m  frase_do_teste\u001b[39m.\u001b[39msplit()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m planilha_limpa \u001b[39m=\u001b[39m mensagem_limpa(train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m dic_probabilidades_por_classe_treino \u001b[39m=\u001b[39m dicionario_prob_palavra_dado_target_treino(planilha_limpa, target)   \u001b[39m#dicionario com as palavras e suas frequencias absolutas\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m dados_target \u001b[39m=\u001b[39m divisao_categorias(planilha_treino_limpa, target)\n",
      "\u001b[1;32mc:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\\#5ALISPACE.ipynb Cell 31\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmensagem_limpa\u001b[39m(planilha):   \u001b[39m#recebe a planilha e cria uma nova planilha com a coluna de mensagem limpa com as frases limpas\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     planilha_limpa \u001b[39m=\u001b[39m planilha\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     planilha_limpa[\u001b[39m'\u001b[39m\u001b[39mMensagem Limpa\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [limpa_tudo(x) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m \u001b[39mlist\u001b[39;49m(planilha[\u001b[39m'\u001b[39;49m\u001b[39mMensagem\u001b[39;49m\u001b[39m'\u001b[39;49m])]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m planilha_limpa\n",
      "\u001b[1;32mc:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\\#5ALISPACE.ipynb Cell 31\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmensagem_limpa\u001b[39m(planilha):   \u001b[39m#recebe a planilha e cria uma nova planilha com a coluna de mensagem limpa com as frases limpas\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     planilha_limpa \u001b[39m=\u001b[39m planilha\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     planilha_limpa[\u001b[39m'\u001b[39m\u001b[39mMensagem Limpa\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [limpa_tudo(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(planilha[\u001b[39m'\u001b[39m\u001b[39mMensagem\u001b[39m\u001b[39m'\u001b[39m])]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m planilha_limpa\n",
      "\u001b[1;32mc:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\\#5ALISPACE.ipynb Cell 31\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m texto \u001b[39m=\u001b[39m limpa_espaco(texto) \u001b[39m#Aplicando a função de limpeza de espaços\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m texto \u001b[39m=\u001b[39m stopwords(texto) \u001b[39m#Removendo stopwords\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m texto \u001b[39m=\u001b[39m lemmat(texto) \u001b[39m#Realiza lemmatização\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mreturn\u001b[39;00m texto\n",
      "\u001b[1;32mc:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\\#5ALISPACE.ipynb Cell 31\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmat\u001b[39m(texto):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     doc \u001b[39m=\u001b[39m nlp(texto)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     lemmat_radicais \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m radicais \u001b[39min\u001b[39;00m doc:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\language.py:1042\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m   1041\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1042\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1044\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\pipeline\\transition_parser.pyx:263\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\pipeline\\transition_parser.pyx:284\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[0;32m    331\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\ml\\tb_framework.py:34\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 34\u001b[0m     step_model \u001b[39m=\u001b[39m ParserStepModel(\n\u001b[0;32m     35\u001b[0m         X,\n\u001b[0;32m     36\u001b[0m         model\u001b[39m.\u001b[39;49mlayers,\n\u001b[0;32m     37\u001b[0m         unseen_classes\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39munseen_classes\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     38\u001b[0m         train\u001b[39m=\u001b[39;49mis_train,\n\u001b[0;32m     39\u001b[0m         has_upper\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39mhas_upper\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m step_model, step_model\u001b[39m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\spacy\\ml\\parser_model.pyx:249\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\layers\\with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[0;32m     41\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\layers\\with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     75\u001b[0m lengths \u001b[39m=\u001b[39m NUMPY_OPS\u001b[39m.\u001b[39masarray1i([\u001b[39mlen\u001b[39m(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m Xs])\n\u001b[0;32m     76\u001b[0m Xf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(Xs, pad\u001b[39m=\u001b[39mpad)\n\u001b[1;32m---> 77\u001b[0m Yf, get_dXf \u001b[39m=\u001b[39m layer(Xf, is_train)\n\u001b[0;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYs: ListXd) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ListXd:\n\u001b[0;32m     80\u001b[0m     dYf \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mflatten(dYs, pad\u001b[39m=\u001b[39mpad)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\layers\\residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m d_output \u001b[39m+\u001b[39m dX\n\u001b[1;32m---> 41\u001b[0m Y, backprop_layer \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](X, is_train)\n\u001b[0;32m     42\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(X, \u001b[39mlist\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m [X[i] \u001b[39m+\u001b[39m Y[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))], backprop\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Função que classifica todas as mensagens da planilha de teste com base na planilha de treino\n",
    "#Fazer meu classificador classificar todas as frases da planilha de teste\n",
    "#recebe a planilha inteira, não precisa realizar nenhuma limpeza\n",
    "from tqdm import tqdm\n",
    "\n",
    "def classifica_planilha(planilha_teste, planilha_treino):\n",
    "    planilha_teste_limpa = mensagem_limpa(planilha_teste)\n",
    "    planilha_treino_limpa = mensagem_limpa(planilha_treino)\n",
    "    avaliacoes_limpas = planilha_teste_limpa[\"Mensagem Limpa\"]\n",
    "    #fez uma cópia da planilha para nao alterar a antiga\n",
    "    planilha_nova = planilha_teste_limpa.copy()\n",
    "    # Criar uma lista para armazenar os resultados do classificador\n",
    "    resultados = []\n",
    "    for frase in tqdm(avaliacoes_limpas, desc=\"Classifying\", unit=\"rows\"):\n",
    "        resultado = classificador(frase, planilha_treino_limpa)\n",
    "        resultados.append(resultado)\n",
    "    # Atribuir a lista de resultados à coluna 'Classificador Automático'\n",
    "    planilha_nova['Classificador Automático'] = resultados\n",
    "    return planilha_nova\n",
    "\n",
    "print(classifica_planilha(test, train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\\#5ALISPACE.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     pct_verdadeiros_N \u001b[39m=\u001b[39m comparador\u001b[39m.\u001b[39miloc[\u001b[39m2\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mN\u001b[39m\u001b[39m'\u001b[39m] \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X43sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m acuracia\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, pct_falsos_A\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, pct_falsos_D\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, pct_falsos_N\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, pct_verdadeiros_A\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, pct_verdadeiros_D\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, pct_verdadeiros_N\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m, comparador\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X43sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m resultados \u001b[39m=\u001b[39m divide_comparativos(train,test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X43sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m verdadeiros_positivos \u001b[39m=\u001b[39m resultados[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aliso/OneDrive%20-%20Insper%20-%20Institudo%20de%20Ensino%20e%20Pesquisa/Insper/2023.2/Ci%C3%AAncia%20de%20Dados/C.DadosP1/%235ALISPACE.ipynb#X43sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m falsos_acionaveis \u001b[39m=\u001b[39m resultados[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "#Função que faz as comparações de acurácia e classificação das mensagens\n",
    "def divide_comparativos(planilha_treino, planilha_teste):\n",
    "\n",
    "    planilha = classifica_planilha(planilha_teste, planilha_treino)\n",
    "    comparador = pd.crosstab(planilha['Classificador Automático'], planilha['Acionável/Direcionável/Não Acionável'],normalize=True, margins=True)\n",
    "\n",
    "    acuracia = comparador.iloc[0]['A'] + comparador.iloc[1]['D'] + comparador.iloc[2]['N'] \n",
    "\n",
    "    pct_falsos_A = comparador.iloc[0]['D'] + comparador.iloc[0]['N']\n",
    "    pct_falsos_D = comparador.iloc[1]['A'] + comparador.iloc[1]['N']\n",
    "    pct_falsos_N = comparador.iloc[2]['D'] + comparador.iloc[2]['A']\n",
    "    pct_verdadeiros_A = comparador.iloc[0]['A']\n",
    "    pct_verdadeiros_D = comparador.iloc[1]['D']\n",
    "    pct_verdadeiros_N = comparador.iloc[2]['N'] \n",
    "\n",
    "    return acuracia*100, pct_falsos_A*100, pct_falsos_D*100, pct_falsos_N*100, pct_verdadeiros_A*100, pct_verdadeiros_D*100, pct_verdadeiros_N*100, comparador\n",
    "\n",
    "resultados = divide_comparativos(train,test)\n",
    "\n",
    "verdadeiros_positivos = resultados[0]\n",
    "falsos_acionaveis = resultados[1]\n",
    "falsos_direcionaveis = resultados[2]\n",
    "falsos_nao_acionaveis = resultados[3]\n",
    "verdadeiros_acionaveis = resultados[4]\n",
    "verdadeiros_direcionaveis = resultados[5]\n",
    "verdadeiros_naoacionaveis = resultados[6]\n",
    "df_crosstab = resultados[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi 83.60% (mensagens corretamente classificadas)\n",
      "A procentagem de falsos acionáveis foi 6.80% (mensagens incorretamente classificadas como acionáveis)\n",
      "A procentagem de falsos direcionáveis foi 6.40% (mensagens incorretamente classificadas como direcionáveis)\n",
      "A procentagem de falsos não acionáveis foi 3.20% (mensagens incorretamente classificadas como não acionáveis)\n",
      "A procentagem de verdadeiros acionáveis foi 10.80% (mensagens corretamente classificadas como acionáveis)\n",
      "A procentagem de verdadeiros direcionáveis foi 13.20% (mensagens corretamente classificadas como direcionáveis)\n",
      "A procentagem de verdadeiros não acionáveis foi 59.60% (mensagens corretamente classificadas como não acionáveis)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Acionável/Direcionável/Não Acionável</th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>N</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificador Automático</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.108</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.144</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.664</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Acionável/Direcionável/Não Acionável      A      D      N    All\n",
       "Classificador Automático                                        \n",
       "A                                     0.108  0.028  0.040  0.176\n",
       "D                                     0.036  0.132  0.028  0.196\n",
       "N                                     0.000  0.032  0.596  0.628\n",
       "All                                   0.144  0.192  0.664  1.000"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printando resultados\n",
    "print(\"A acurácia foi {0:.2f}% (mensagens corretamente classificadas)\".format(verdadeiros_positivos))\n",
    "print(\"A procentagem de falsos acionáveis foi {0:.2f}% (mensagens incorretamente classificadas como acionáveis)\".format(falsos_acionaveis))\n",
    "print(\"A procentagem de falsos direcionáveis foi {0:.2f}% (mensagens incorretamente classificadas como direcionáveis)\".format(falsos_direcionaveis))\n",
    "print(\"A procentagem de falsos não acionáveis foi {0:.2f}% (mensagens incorretamente classificadas como não acionáveis)\".format(falsos_nao_acionaveis))\n",
    "print(\"A procentagem de verdadeiros acionáveis foi {0:.2f}% (mensagens corretamente classificadas como acionáveis)\".format(verdadeiros_acionaveis))\n",
    "print(\"A procentagem de verdadeiros direcionáveis foi {0:.2f}% (mensagens corretamente classificadas como direcionáveis)\".format(verdadeiros_direcionaveis))\n",
    "print(\"A procentagem de verdadeiros não acionáveis foi {0:.2f}% (mensagens corretamente classificadas como não acionáveis)\".format(verdadeiros_naoacionaveis))\n",
    "#cruzamento de dados da planilha\n",
    "df_crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dica: apresentar um grafico com testes mostrando quais limpezas melhoraram a acurácia do nosso classificador (lemmatization, stopwords, etc)\n",
    "\n",
    "REtirar algumas palavras para ver se melhora a qualidade do classificador (exemplo palavra não)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
