{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Alison Araujo\n",
    "\n",
    "Nome: Gabrielly Carneiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading word_tokenize: Package 'word_tokenize' not\n",
      "[nltk_data]     found in index\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('word_tokenize')\n",
    "stopwordsdic = stopwords.words('portuguese')\n",
    "\n",
    "from spacy import load\n",
    "nlp = load('pt_core_news_md')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\gabri\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Projeto 1\\C.DadosP1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Acionável/Direcionável/Não Acionável</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Para quem gosta de poemas simples, esse é o li...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quando vi o lançamento pensei que finalmente p...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>É incrível como esses escritores e \"intelectua...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Se desse pra devolver eu devolvia, nao é por e...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Futilidade, inutilidade, desperdício de papel,...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  \\\n",
       "0  Para quem gosta de poemas simples, esse é o li...   \n",
       "1  Quando vi o lançamento pensei que finalmente p...   \n",
       "2  É incrível como esses escritores e \"intelectua...   \n",
       "3  Se desse pra devolver eu devolvia, nao é por e...   \n",
       "4  Futilidade, inutilidade, desperdício de papel,...   \n",
       "\n",
       "  Acionável/Direcionável/Não Acionável  \n",
       "0                                    N  \n",
       "1                                    D  \n",
       "2                                    N  \n",
       "3                                    N  \n",
       "4                                    N  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('dados_treino.xlsx')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Acionável/Direcionável/Não Acionável</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O livro é prolixo, redundante, doentio. Sou su...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bom livro e história envolvente. Porém, o leit...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fala tudo que todos já sabem, sem falar que nã...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ganhei na compra do Kindle. Não é estilo de li...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Custa crer que um livro tão medíocre, embora m...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  \\\n",
       "0  O livro é prolixo, redundante, doentio. Sou su...   \n",
       "1  Bom livro e história envolvente. Porém, o leit...   \n",
       "2  Fala tudo que todos já sabem, sem falar que nã...   \n",
       "3  Ganhei na compra do Kindle. Não é estilo de li...   \n",
       "4  Custa crer que um livro tão medíocre, embora m...   \n",
       "\n",
       "  Acionável/Direcionável/Não Acionável  \n",
       "0                                    N  \n",
       "1                                    D  \n",
       "2                                    N  \n",
       "3                                    N  \n",
       "4                                    N  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('dados_teste.xlsx')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo do seguinte projeto é desenvolver um classificador de texto automático a partir das hipóteses de Naive-Bayes. Para isso, o classificador será treinado com uma base de dados de reviews de livros vendidos pela Amazon, e sua performance será testada ao classificar mensagens de uma base de teste. Para isso, o projeto foi dividido nas seguintes etapas:\n",
    "\n",
    "* Coleta de dados: o primeiro passo foi coletar os reviews dos livros em planilhas de treino (avaliações que serviram como base para o treino do classificador) e de teste (avaliações que verificam a acurácia do classificador);\n",
    "\n",
    "* Classificação manual: a partir dos dados extraídos, foi feita a classificação manual de cada review, tanto da base de treino quanto de teste, considerando-se três possíveis classes/targets: Acionável, Direcionável e Não Acionável. Os critérios para essa classificação manual estão resumidos abaixo:\n",
    "    - Acionável: para ser considerado \"acionável\" (\"A\") o review deve ser passível de alguma ação pela Amazon, ou seja, o review deve ser sobre entrega, estado do produto, contato com o suporte, etc;\n",
    "    - Direcionável: para o target \"direcionável\" (\"D\") foram considerados comentários relativos à editora, como qualidade do material do livro, preço do livro e do e-book, tradução e edição;\n",
    "    - Não Acionáveis: por fim, os não acionáveis (\"N\") eram comentários relativos ao autor, ao apreço pelo conteúdo do livro, ou comentários irrelavantes;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Montando um classificador Naive-Bayes: para montar o classificador consideramos verdadeira a hipótese de Naive-Bayes: as probabilidades de ocorrência de cada palavra dentro de uma classe são independentes e a ordem das palavras dentro da frase não importa. Além disso, nessa etapa foram criadas as funções para calcular as probabilidades de cada frase ocorrer em uma classe. Dentro dessas funções utilizamos conceitos de probabilidade condicional e de suavização de LaPlace, que serão explicados a seguir;\n",
    "\n",
    "* Verificando a performance do classificador: nesse tópico finalmente aplicamos o classificador automático: treinamos ele com a planilha \"train\", contento 500 reviews, e testamos sua performance para classificar 250 reviews da planilha \"test\". \n",
    "\n",
    "Ao final, traremos conclusões a respeito da performance do classificador em diferentes cenários, bem como gráficos apresentando a qualidade do classificador a partir de novas separações de base de teste e treino.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilidade condicional\n",
    "\n",
    "Para classificar as frases em cada categoria, devemos utilizar a fórmula de probabilidade condicional abaixo:\n",
    "\n",
    "$$P(classe|frase) = \\frac{P(frase|classe)*P(classe)}{P(frase)}$$\n",
    "\n",
    "Como nosso objetivo é fazer um comparador, não será necessário encontrar a probabilidade de cada frase, pois independente da categoria essa probabilidade será a mesma. \n",
    "\n",
    "O cálculo de $P(frase|classe)$ será dado por:\n",
    "\n",
    "$$\\quad P(frase|classe) = \n",
    "P(pal_1|classe)\\cdot P(pal_2|classe)\\cdot P(pal_3|classe)\\cdot P(pal_4|classe)\\cdot ... \\cdot P(pal_n|classe)$$\n",
    "\n",
    "Por fim, teremos:\n",
    "\n",
    "\n",
    "$$P(classe|frase) = \\frac{P(pal_1|classe)\\cdot P(pal_2|classe)\\cdot P(pal_3|classe)\\cdot P(pal_4|classe)\\cdot ... \\cdot P(pal_n|classe)*P(classe)}{P(frase)}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suavização de LaPlace\n",
    "\n",
    "Vimos acima que para o cálculo da probabilidade de uma frase (um review) estar contido em um target/classe é preciso saber a probabilidade de cada palavra estar contida naquele target. Contudo, isso pode ser um problema caso essa palavra não esteja contida na minha base de dados. Note que caso a palavra não exista no meu vocabulário, a probabilidade dela ocorrer em qualquer classe seria zero; isso faria com que a probabilidade da frase ocorrer também fosse nula, o que não é verdade. Para corrigir esse erro, utiliza-se uma ferramenta bastante útil, chamada suavização de LaPlace. Aplicaremos a suavização para todas as palavras do vocabulário e, principalmente, a aplicaremos quando o classificador encontrar palavras que não estejam contidas no vocabulário. \n",
    "\n",
    "A fórmula que nos permite aplicar a suavização de LaPlace para uma determinada categoria é dada por:\n",
    "\n",
    "\n",
    "$$ P(palavra|classe) = \\frac{n_{Palavra na Classe} + \\\\\\alpha}{n_{Total de Palavras} + \\\\\\alpha . n_{Total de Palavras Sem Repeticao}}$$\n",
    "\n",
    "Sendo:\n",
    "- $P(palavra|classe)$ é a probabilidade da palavra estar contida na classe\n",
    "- $n_{Palavra na Classe}$ é o número de ocorrências daquela palavra na classe, isto é, sua frequência absoluta na classe\n",
    "- $n_{Total de Palavras}$ é o número total de palavras que existem naquela classe\n",
    "- $n_{Total de Palavras Sem Repeticao}$ é o número total de palavras sem repetição que existem naquela classe \n",
    "- $\\\\\\alpha$ é o fator de suavização \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções úteis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar uma função que transforma as frases da planilha em um texto só \n",
    "    #(Será útil para criar o dicionário com as palavras)\n",
    "\n",
    "def transforma_em_string(coluna):\n",
    "    texto = ''\n",
    "    for linha in coluna:\n",
    "        texto += linha + ' '\n",
    "    return texto    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar uma função que limpa todas as pontuações\n",
    "#recebe um texto\n",
    "#vou utilizar ela na função limpa tudo\n",
    "def cleanup(text):\n",
    "    punctuation = r'[´\"\\'!-.:?;$,/~^_=+*&¨%$#@|\\{}()[\\]]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma função que limpa os espaços duplicados\n",
    "#vou utilizar ela na função limpa tudo\n",
    "def limpa_espaco(text):\n",
    "    punctuation = r'[\\n]'  # Adicione os caracteres desejados aqui\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma função para remover emoji\n",
    "#vou utilizar ela na função limpa tudo\n",
    "def remove_emoji(text):\n",
    "    text_without_emojis = unidecode(text)\n",
    "    return text_without_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a função de stopwords\n",
    "#vou utilizar ela na função limpa tudo\n",
    "#vai receber o texto limpo pelas outras funções\n",
    "def stopwords(texto):\n",
    "    palavras = word_tokenize(texto, language='portuguese') # Tokenize é analisar palavras individualmente, basicamente\n",
    "    palavras_sem_stopword = []\n",
    "    for palavra in palavras:\n",
    "        if palavra not in stopwordsdic:\n",
    "            palavras_sem_stopword.append(palavra)\n",
    "    # Reúna as palavras sem stopwords em uma string novamente\n",
    "    texto_sem_stopword = ' '.join(palavras_sem_stopword)\n",
    "    return texto_sem_stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a função de lematização\n",
    "#vou utilizar ela na função limpa tudo\n",
    "#vai receber o texto limpo pelas outras funções, incluindo limpeza de stopwords\n",
    "\n",
    "def lemmat(texto):\n",
    "    doc = nlp(texto)\n",
    "    lemmat_radicais = []\n",
    "    for radicais in doc:\n",
    "        lemmat_radicais.append(radicais.lemma_)\n",
    "    texto_lemmat = ' '.join(lemmat_radicais)    \n",
    "    return texto_lemmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cria uma função que reúna as funções de limpeza\n",
    "def limpa_tudo(mensagem):\n",
    "    #Aplicando a função de limpeza de pontuação\n",
    "    texto = cleanup(mensagem)\n",
    "    #Deixando tudo em letra minúscula\n",
    "    texto = texto.lower()\n",
    "    #Removendo emoji\n",
    "    texto = remove_emoji(texto)\n",
    "    #Aplicando a função de limpeza de espaço\n",
    "    texto = limpa_espaco(texto)\n",
    "    #Removendo stopwords\n",
    "    texto = stopwords(texto)\n",
    "    #Realiza lemmatização\n",
    "    texto = lemmat(texto)  \n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma função que limpa as linhas da planilha e adiciona uma coluna com as mensagens limpas à planilha\n",
    "def mensagem_limpa(planilha):   #recebe a planilha e cria uma nova planilha com a coluna de mensagem limpa com as frases limpas\n",
    "    planilha_limpa = planilha.copy()\n",
    "    planilha_limpa['Mensagem Limpa'] = [limpa_tudo(x) for x in list(planilha['Mensagem'])]\n",
    "    return planilha_limpa    #retorna a planilha modificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria função que cria o vocabulário de tudo\n",
    "def cria_vocabulario(coluna_mensagem_limpa_da_planilha_limpa):                       #recebe uma coluna da planilha\n",
    "    lista_palavras = transforma_em_string(coluna_mensagem_limpa_da_planilha_limpa)\n",
    "    lista_palavras = lista_palavras.split()\n",
    "    return lista_palavras     #devolve uma lista com as palavras separadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria função que retorna uma lista sem as palavras repetidas\n",
    "def remove_repeticao(lista_de_palavras):\n",
    "    dic = set(lista_de_palavras)\n",
    "    lista_vocabulario_sem_repeticao = list(dic)\n",
    "    return lista_vocabulario_sem_repeticao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma função que guarda as palavras em pd.Series e calculas frequencia (relativa e absoluta) das palavras\n",
    "#recebe uma lista (devolvida pelo cria vocabulário, preferencialmente)\n",
    "def cria_pdseries(lista):\n",
    "    tabela = pd.Series(lista)\n",
    "    return tabela\n",
    "\n",
    "#Cria uma função que retorna a frequência absoluta de cada palavra no texto\n",
    "#recebe uma tabela de pd\n",
    "def freq_abs(tabela):\n",
    "    absoluta = tabela.value_counts()\n",
    "    return absoluta\n",
    "\n",
    "#Cria uma função que retorna a frequência relativa de cada palavra no texto\n",
    "def freq_rel(tabela):\n",
    "    relativa = tabela.value_counts(True)\n",
    "    return relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria função de divisão com base nas categorias/targets\n",
    "## Cria uma função que recebe a planilha e o target e \n",
    "# retorna o total de palavras e as tabelas de frequencia absoluta e relativa e o vocabulario sem palavras repetidas, nessa ordem\n",
    "#vou falar que ela recebe a planilha limpa já\n",
    "\n",
    "def divisao_categorias(planilha_limpa, target):\n",
    "    #Etapa de divisão de categorias     \n",
    "    #criou uma nova planilha apenas com as linha com aquele target                \n",
    "    filtro_target = planilha_limpa.loc[planilha_limpa['Acionável/Direcionável/Não Acionável'] == target]\n",
    "    vocab_target = cria_vocabulario(filtro_target[\"Mensagem Limpa\"]) #vocabulario daquele target\n",
    "    df_vocab_target = cria_pdseries(vocab_target)\n",
    "    freq_rel_target = freq_rel(df_vocab_target)\n",
    "    freq_abs_target = freq_abs(df_vocab_target)   #frequencia de palavras daquele target\n",
    "    total_target = freq_abs_target.sum()  #total de palavras daquele target\n",
    "    #criar vocabulario limpo\n",
    "    vocab_target_sr = remove_repeticao(vocab_target)   #vocabulario do target sem palavras repetidas\n",
    "    return total_target, freq_abs_target, freq_rel_target, vocab_target_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que realiza a divisão de toda a planilha \n",
    "# # Função que recebe a planilha já limpa e retorna:\n",
    "# o total de palavras com repetição [0] (int)\n",
    "# a tabela com a frequência absoluta de cada palavra na planilha [1] (Series)\n",
    "# a tabela com a frequência relativa de cada palavra na planilha [2] (Series)\n",
    "# a lista com todas as palavras da planilha sem repetição [3] (list)\n",
    "def divisao_planilhas(planilha_limpa):\n",
    "    \n",
    "    coluna_limpa = planilha_limpa[\"Mensagem Limpa\"]                   #separa só a coluna \"Mensagem Limpa\"\n",
    "    vocab_planilha = cria_vocabulario(coluna_limpa)             #lista de palavras na coluna \"Mensagem Limpa\"\n",
    "    df_vocab_planilha = cria_pdseries(vocab_planilha)       #coloca essa lista em um df\n",
    "    freq_abs_planilha = freq_abs(df_vocab_planilha)         #calcula a frequência absoluta de cada palavra\n",
    "    freq_rel_planilha = freq_rel(df_vocab_planilha)         #calcula a frequência relativa de cada palavra\n",
    "    total_planilha = freq_abs_planilha.sum()                #calcula o total de palavras com repetição\n",
    "    vocab_planilha_sr = remove_repeticao(vocab_planilha)       #vocabulario sem repeticao (é uma lista)\n",
    "\n",
    "    return total_planilha, freq_abs_planilha, freq_rel_planilha, vocab_planilha_sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que cria um dicionário com as palavras e as frequencias absolutas\n",
    "\n",
    "#vou criar um dicionário com todas as palavras e seus valores de \n",
    "# frequencia absoluta para cada target\n",
    "# aí vai ficar mais rapido de encontrar os valores\n",
    "# do que ter que suavizar pra cada palavra toda vez\n",
    "# que chamar o loop\n",
    "def dicionario_prob_palavra_dado_target_treino(planilha_treino_limpa, target):\n",
    "    coluna_limpa = planilha_treino_limpa[\"Mensagem Limpa\"]\n",
    "    dados_target = divisao_categorias(planilha_treino_limpa, target)\n",
    "    # frequencias_relativas = dados_target[2]\n",
    "    frequencias_absolutas = dados_target[1]\n",
    "\n",
    "    dic_treino = {} \n",
    "    \n",
    "    for frase in coluna_limpa:\n",
    "        frase = frase.split()\n",
    "        for palavra in frase:\n",
    "            if palavra not in dic_treino:\n",
    "                if palavra in frequencias_absolutas:\n",
    "                    freq_abs_palavra = frequencias_absolutas[palavra]\n",
    "                    dic_treino[palavra] = freq_abs_palavra\n",
    "    return dic_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que calcula probabidade da frase dado target realizando suavização de LaPlace\n",
    "# Probabilidade da frase dado target mais suavização de LaPlace\n",
    "def frase_dado_target(frase_do_teste, target, planilha_treino_limpa):\n",
    "    prob_frase_dado_classe = 1\n",
    "    frase_do_teste =  frase_do_teste.split()\n",
    "    dic_probabilidades_por_classe_treino = dicionario_prob_palavra_dado_target_treino(planilha_treino_limpa, target)   #dicionario com as palavras e suas frequencias absolutas\n",
    "    dados_target = divisao_categorias(planilha_treino_limpa, target)\n",
    "    qtdd_palavras = dados_target[0]                  #quantidade de palavras no target informado\n",
    "    qtdd_palavras_sem_repeticao = len(dados_target[3]) \n",
    "    \n",
    "    alfa = 0.01\n",
    "    for palavra in frase_do_teste:\n",
    "        if palavra in dic_probabilidades_por_classe_treino:\n",
    "            freq_abs_palavra = dic_probabilidades_por_classe_treino[palavra]\n",
    "            #APLIQUEI A SUAVIZAÇÃO DE LA PLACE\n",
    "            prob_palavra_dado_classe = (freq_abs_palavra + alfa)/(qtdd_palavras + alfa*qtdd_palavras_sem_repeticao)\n",
    "            prob_frase_dado_classe *= prob_palavra_dado_classe\n",
    "        else:\n",
    "            freq_abs_palavra = 0\n",
    "            #APLIQUEI A SUAVIZAÇÃO DE LA PLACE\n",
    "            prob_palavra_dado_classe = (freq_abs_palavra + alfa)/(qtdd_palavras + alfa*qtdd_palavras_sem_repeticao)\n",
    "            prob_frase_dado_classe *= prob_palavra_dado_classe\n",
    "    return prob_frase_dado_classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de classificação das frases (quanto a acionável, não acionável e direcionável)\n",
    "#recebe a planilha já limpa\n",
    "def classificador(frase_do_teste, planilha_treino):\n",
    "    \n",
    "    #Extraindo as informações\n",
    "    total_planilha_N = divisao_categorias(planilha_treino, \"N\")[0]\n",
    "    total_planilha_D = divisao_categorias(planilha_treino, \"D\")[0]\n",
    "    total_planilha_A = divisao_categorias(planilha_treino, \"A\")[0]\n",
    "    total_planilha = divisao_planilhas(planilha_treino)[0]\n",
    "    \n",
    "    #Cálculo das probabilidades\n",
    "    P_frase_dado_A = frase_dado_target(frase_do_teste, \"A\", planilha_treino)\n",
    "    P_frase_dado_D = frase_dado_target(frase_do_teste, \"D\", planilha_treino)\n",
    "    P_frase_dado_N = frase_dado_target(frase_do_teste, \"N\", planilha_treino)\n",
    "    P_N = total_planilha_N/total_planilha         #probabilidade de estar na categoria N\n",
    "    P_D = total_planilha_D/total_planilha         #probabilidade de estar na categoria D\n",
    "    P_A = total_planilha_A/total_planilha         #probabilidade de estar na categoria A\n",
    "    \n",
    "    P_A_dado_frase = P_frase_dado_A*P_A\n",
    "    P_N_dado_frase = P_frase_dado_N*P_N\n",
    "    P_D_dado_frase = P_frase_dado_D*P_D\n",
    "        \n",
    "    #Classificação\n",
    "    if P_A_dado_frase >= P_D_dado_frase and P_A_dado_frase >= P_N_dado_frase:    #na classificação manual quando impatava a prioridade era acionável\n",
    "        return \"A\"\n",
    "    elif P_D_dado_frase > P_N_dado_frase and P_D_dado_frase > P_A_dado_frase:\n",
    "        return \"D\"\n",
    "    elif P_N_dado_frase > P_D_dado_frase and P_N_dado_frase > P_A_dado_frase:\n",
    "        return \"N\"\n",
    "    else:\n",
    "        return \"Houve um impasse\"    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que classifica todas as mensagens da planilha de teste com base na planilha de treino\n",
    "#Fazer meu classificador classificar todas as frases da planilha de teste\n",
    "#recebe a planilha inteira, não precisa realizar nenhuma limpeza\n",
    "def classifica_planilha(planilha_teste, planilha_treino):\n",
    "    planilha_teste_limpa = mensagem_limpa(planilha_teste)\n",
    "    planilha_treino_limpa = mensagem_limpa(planilha_treino)\n",
    "    avaliacoes_limpas = planilha_teste_limpa[\"Mensagem Limpa\"]\n",
    "    #fez uma cópia da planilha para nao alterar a antiga\n",
    "    planilha_nova = planilha_teste_limpa.copy()\n",
    "    # Criar uma lista para armazenar os resultados do classificador\n",
    "    resultados = []\n",
    "    for frase in avaliacoes_limpas:\n",
    "        resultado = classificador(frase, planilha_treino_limpa)\n",
    "        resultados.append(resultado)\n",
    "    # Atribuir a lista de resultados à coluna 'Classificador Automático'\n",
    "    planilha_nova['Classificador Automático'] = resultados\n",
    "    return planilha_nova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que faz as comparações de acurácia e classificação das mensagens\n",
    "def divide_comparativos(planilha_treino, planilha_teste):\n",
    "\n",
    "    planilha = classifica_planilha(planilha_teste, planilha_treino)\n",
    "    comparador = pd.crosstab(planilha['Classificador Automático'], planilha['Acionável/Direcionável/Não Acionável'],normalize=True, margins=True)\n",
    "    acuracia = comparador.iloc[0]['A'] + comparador.iloc[1]['D'] + comparador.iloc[2]['N'] \n",
    "\n",
    "    pct_falsos_A = comparador.iloc[0]['D'] + comparador.iloc[0]['N']\n",
    "    pct_falsos_D = comparador.iloc[1]['A'] + comparador.iloc[1]['N']\n",
    "    pct_falsos_N = comparador.iloc[2]['D'] + comparador.iloc[2]['A']\n",
    "    pct_verdadeiros_A = comparador.iloc[0]['A']\n",
    "    pct_verdadeiros_D = comparador.iloc[1]['D']\n",
    "    pct_verdadeiros_N = comparador.iloc[2]['N'] \n",
    "\n",
    "    return acuracia*100, pct_falsos_A*100, pct_falsos_D*100, pct_falsos_N*100, pct_verdadeiros_A*100, pct_verdadeiros_D*100, pct_verdadeiros_N*100, comparador\n",
    "\n",
    "resultados = divide_comparativos(train,test)\n",
    "\n",
    "verdadeiros_positivos = resultados[0]\n",
    "falsos_acionaveis = resultados[1]\n",
    "falsos_direcionaveis = resultados[2]\n",
    "falsos_nao_acionaveis = resultados[3]\n",
    "verdadeiros_acionaveis = resultados[4]\n",
    "verdadeiros_direcionaveis = resultados[5]\n",
    "verdadeiros_naoacionaveis = resultados[6]\n",
    "df_crosstab = resultados[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia foi 83.20% (mensagens corretamente classificadas)\n",
      "A procentagem de falsos acionáveis foi 8.00% (mensagens incorretamente classificadas como acionáveis)\n",
      "A procentagem de falsos direcionáveis foi 6.00% (mensagens incorretamente classificadas como direcionáveis)\n",
      "A procentagem de falsos não acionáveis foi 2.80% (mensagens incorretamente classificadas como não acionáveis)\n",
      "A procentagem de verdadeiros acionáveis foi 11.20% (mensagens corretamente classificadas como acionáveis)\n",
      "A procentagem de verdadeiros direcionáveis foi 12.80% (mensagens corretamente classificadas como direcionáveis)\n",
      "A procentagem de verdadeiros não acionáveis foi 59.20% (mensagens corretamente classificadas como não acionáveis)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Acionável/Direcionável/Não Acionável</th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>N</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificador Automático</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.112</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.144</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.664</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Acionável/Direcionável/Não Acionável      A      D      N    All\n",
       "Classificador Automático                                        \n",
       "A                                     0.112  0.036  0.044  0.192\n",
       "D                                     0.032  0.128  0.028  0.188\n",
       "N                                     0.000  0.028  0.592  0.620\n",
       "All                                   0.144  0.192  0.664  1.000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printando resultados\n",
    "print(\"A acurácia foi {0:.2f}% (mensagens corretamente classificadas)\".format(verdadeiros_positivos))\n",
    "print(\"A procentagem de falsos acionáveis foi {0:.2f}% (mensagens incorretamente classificadas como acionáveis)\".format(falsos_acionaveis))\n",
    "print(\"A procentagem de falsos direcionáveis foi {0:.2f}% (mensagens incorretamente classificadas como direcionáveis)\".format(falsos_direcionaveis))\n",
    "print(\"A procentagem de falsos não acionáveis foi {0:.2f}% (mensagens incorretamente classificadas como não acionáveis)\".format(falsos_nao_acionaveis))\n",
    "print(\"A procentagem de verdadeiros acionáveis foi {0:.2f}% (mensagens corretamente classificadas como acionáveis)\".format(verdadeiros_acionaveis))\n",
    "print(\"A procentagem de verdadeiros direcionáveis foi {0:.2f}% (mensagens corretamente classificadas como direcionáveis)\".format(verdadeiros_direcionaveis))\n",
    "print(\"A procentagem de verdadeiros não acionáveis foi {0:.2f}% (mensagens corretamente classificadas como não acionáveis)\".format(verdadeiros_naoacionaveis))\n",
    "#cruzamento de dados da planilha\n",
    "df_crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conclusões Gerais "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia do classificador automático para essas base de treino e teste foi de 83.2%. \n",
    "\n",
    "A partir da análise qualitativa dos percentuais de acertos obtidos no item Verificando a Performance do Classificador, podemos concluir que o melhor desempenho do classificador ocorre na categoria \"Não Acionável\", com a maior porcentagem de acertos na classificação, e menor porcentagem de erros (4,72% de erro em relação a quantidade de acertos nessa categori).\n",
    "\n",
    "Para a categoria direcionáveis, o percentual de erros comparados ao percentual de acertos foi de aproximandamente 47%, o que representa uma certa dificuldade do classificador para identificar essas frases.\n",
    "\n",
    "O pior desempenho, no entanto, ocorre para a categoria Acionáveis, visto que o percentual de acertos é bastante comparável ao percentual de erros (o percentual de erros representa cerca de 71.43% dos acertos). Ou seja, se o objetivo principal do classificador é direcionar mensagens acionáveis para a Amazon, seu desempenho não se mostra tão satisfatório, ainda que para esse caso nenhuma frase Acionável foi considerada irrelevante (Não Acionável).\n",
    "\n",
    "* Possíveis melhorias\n",
    "\n",
    "Uma melhoria significativa para aprimorar o classificador Naive-Bayes é a ampliação de sua base de dados de treino, desde que a distribuição entre categorias/targets seja comparável. Desse modo, quanto mais dados de treino, mais evidências o classificador tem para aprender padrões, o que levaria a melhores cálculos das probabilidades de ocorrência de cada frase em cada um dos targets. Além disso, uma base de dados de treino maior pode conter mais diversidade e complexidade dos casos reais, o que ajuda o classificador a lidar com situações novas e imprevistas. Essa ampliação poderia ser feita classificando manualmente mais reviews e fornecendo-os para o classificador.\n",
    "\n",
    "$Referência:$ livro \"Pattern Recognition and Machine Learning\" de Christopher M. Bishop. Embora este livro não seja especificamente sobre Naive Bayes, ele discute como o aumento do tamanho da base de dados de treinamento pode melhorar o desempenho dos modelos.\n",
    "\n",
    "Além disso, podemos pensar em outras estratégias para a melhoria do nosso classificador. Por exemplo, notaremos abaixo que o classificador consegue tratar adequadamente frases com dupla negação ou com sarcasmos, mas não consegue diferenciar tão bem as categorias Acionável e Direcionável. Uma ideia para a expansão e nova iteração para esse projeto seria treiná-lo mais uma vez com as frases Acionáveis e Direcionáveis: ou seja, realizar duas classificações. Na primeira, manteríamos as três classificações (A, D e N). Em seguida, poderíamos descartar as frases classificadas como Não Acionáveis (que apresentam pequeno percentual de erro). Por fim, realizaríamos novo treinamento somente considerando as frases Acionáveis e Direcionáveis, para então reclassificar as frases como A ou D.\n",
    "$$Referência: https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/$$\n",
    "\n",
    "Ou seja, embora o classificador ainda apresente erros consideráveis nas classificações, sua expansão poderia levar a melhorias significativas nos resultados, mostrando-se uma ferramenta útil para a Amazon direcionar reclamações ou tomar medidas para o atendimento do consumidor. De todo modo, mesmo sem uma nova iteração o classificador funciona como um bom filtro para descartar mensagens \"não acionáveis\", ou seja, elimina avaliações irrelevantes para a empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por que não podemos utilizar o próprio classificador para gerar mais amostras de treinamento?\n",
    "\n",
    "A criação de novos dados para alimentar a base de treino a partir do classificador Naive-Bayes é incorreta pois o classificador não é capaz de \"criar\" conteúdo, apenas de reproduzir o que lhe foi ensinado manualmente. Além disso, o classificador geraria dados enviesados que propagariam os erros já cometidos por ele, uma vez que seria incapaz de melhorar efetivamente sua base de dados.\n",
    "\n",
    "O classificador Naive assume, ainda, que as palavras são independentes entre si, o que, em suma, não é verdade, já que muitas vezes a disposição das palavras é fundamental para sua total compreensão. Isto é, caso o classificador automático fosse utilizado para criar dados, suas criações provavelmente seriam desconexas também. \n",
    "\n",
    "Portanto, é incoerente utilizar o classificador Naive-Bayes com o objetivo de gerar novos dados para a base de treinamento, pois em síntese, esses dados não seriam novos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise Qualitativa\n",
    "\n",
    "Pensando em apurar a performance do classificador, propomos aqui a análise qualitativa do desempenho do classificador automático em diferentes cenários.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Primeiro cenário: análise de frases ambíguas\n",
    "\n",
    "Nesse primeiro caso, temos a intenção de analisar o comportamento do classificador diante de mensagens que podem ser ambíguas, ou seja, poderiam ser classificadas tanto como acionáveis, quanto como direcionáveis.\n",
    "\n",
    "Frase: \"As páginas desse livro têm uma péssima qualidade, são extremamente finas e fáceis de rasgar. Além disso o box chegou todo rasgado e a entrega foi demorada\"\n",
    "\n",
    "Essa frase deveria ser classificada como Acionável, visto que durante a classificação manual as reclamações quanto à amazon (acionáveis) deveriam ter prioridade. Vamos então verificar o que acontece com ela quando utilizamos nosso classificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como a função classificador recebe a planilha com as mensagens limpas, vamos realizar essa limpeza para todas as estapas abaixo\n",
    "planilha_limpa = mensagem_limpa(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase foi classificada como D\n"
     ]
    }
   ],
   "source": [
    "frase1 = \"As páginas desse livro têm uma péssima qualidade, são extremamente finas e fáceis de rasgar. Além disso o box chegou todo rasgado e a entrega foi demorada\"\n",
    "#como a frase precisa estar limpa, realizamos as limpezas do texto:\n",
    "#vou criar uma pequena função para classificar rapidamente as frases\n",
    "def classifica_frase(frase, planilha_limpa):\n",
    "    frase = limpa_tudo(frase)\n",
    "    classificacao = classificador(frase, planilha_limpa)\n",
    "    return classificacao\n",
    "\n",
    "print(\"A frase foi classificada como {0}\".format(classifica_frase(frase1, planilha_limpa)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, a frase foi classificada como Direcionável, o que representa uma incoerência do nosso classificador. Vamos então realizar alguns testes, como remoção de palavras, para avaliar se nosso classificador interpreta de outra maneira.\n",
    "\n",
    "Frase = \"Esse livro têm uma péssima qualidade. Além disso o box chegou todo rasgado e a entrega foi demorada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase foi classificada como D\n"
     ]
    }
   ],
   "source": [
    "frase1 = \"Esse livro têm uma péssima qualidade. Além disso o box chegou todo rasgado e a entrega foi demorada\"\n",
    "print(\"A frase foi classificada como {0}\".format(classifica_frase(frase1, planilha_limpa)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, a classificação foi incorreta. Realizando uma nova iteração:\n",
    "\n",
    "Frase = \"Péssima qualidade. Além disso o box chegou todo rasgado e a entrega foi demorada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase foi classificada como D\n"
     ]
    }
   ],
   "source": [
    "frase1 = \"Péssima qualidade. Além disso o box chegou todo rasgado e a entrega foi demorada\"\n",
    "print(\"A frase foi classificada como {0}\".format(classifica_frase(frase1, planilha_limpa)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, percebemos que apesar de não haver nenhuma citação direta quanto à qualidade das páginas ou da edição, ainda assim a frase foi classificada como Direcionável. Vamos, por fim, remover qualquer menção à qualidade:\n",
    "\n",
    "Frase = \"O box chegou todo rasgado e a entrega foi demorada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase foi classificada como A\n"
     ]
    }
   ],
   "source": [
    "frase1 = \"O box chegou todo rasgado e a entrega foi demorada\"\n",
    "print(\"A frase foi classificada como {0}\".format(classifica_frase(frase1, planilha_limpa)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somente nessa frase ela foi corretamente classificada. Ou seja, notamos que nosso classificador apresenta uma falha ao diferenciar frases com ambiguidade, que deveriam, por prioridade da classificação manual, ser classificadas como Acionável (para a Amazon). \n",
    "\n",
    "Uma das principais hipóteses para explicar essa falha é a de que a base de treino do nosso classificador continha pouquíssimas frases que reclamavam tanto da editora quanto da Amazon, de modo que não foi possível treinar corretamente o classificador para distinguir essas informações.\n",
    "\n",
    "Vamos agora analisar uma frase que poderia ser classificada como Não Acionável e como Acionável, como por exemplo:\n",
    "\n",
    "Frase = \"Esse livro não tem nada de interessante, história básica, personagens sem graça e descrições muito longas. Além disso, a entrega chegou atrasada e em péssimas condições\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase foi classificada como N\n"
     ]
    }
   ],
   "source": [
    "frase = \"Esse livro não tem nada de interessante, história básica, personagens sem graça e descrições muito longas. Além disso, a entrega chegou atrasada e em péssimas condições\"\n",
    "print(\"A frase foi classificada como {0}\".format(classifica_frase(frase, planilha_limpa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase foi classificada como D\n"
     ]
    }
   ],
   "source": [
    "frase = \"Esse livro não tem nada de interessante. Além disso, a entrega chegou atrasada e em péssimas condições\"\n",
    "print(\"A frase foi classificada como {0}\".format(classifica_frase(frase, planilha_limpa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase foi classificada como D\n"
     ]
    }
   ],
   "source": [
    "frase = \"Nada de interessante. Além disso, a entrega chegou atrasada e em péssimas condições\"\n",
    "print(\"A frase foi classificada como {0}\".format(classifica_frase(frase, planilha_limpa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase foi classificada como A\n"
     ]
    }
   ],
   "source": [
    "frase = \"A entrega chegou atrasada e em péssimas condições\"\n",
    "print(\"A frase foi classificada como {0}\".format(classifica_frase(frase, planilha_limpa)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos perceber, o classificador de fato apresenta problemas em diferenciar frases com diferentes posíveis classificações. Além disso, ele classificou incorretamente a frase como Direcionável, enquanto deveria ter classificado como Acionável. \n",
    "Novamente, essa incoerência pode estar relacionada à pobreza da base de treino quanto à classificações Acionáveis e Direcionáveis. \n",
    "\n",
    "Fazendo uma breve análise quantitativa na distribuição de dados da planilha de treino, podemos observar a quantidade de classificações manuais como Acionável, Direcionável e Não Acionável. Veja na célula abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de frases manualmente classificadas foi:\n",
      "Acionáveis = 15.60%\n",
      "Direcionáveis = 20.20%\n",
      "Não Acionáveis = 64.20%\n"
     ]
    }
   ],
   "source": [
    "#cria uma pequena função para calcular as ocorrências de cada target na planilha\n",
    "def filtro (planilha_limpa, target):\n",
    "    filtro_target = planilha_limpa.loc[planilha_limpa['Acionável/Direcionável/Não Acionável'] == target]\n",
    "    return len(filtro_target)\n",
    "\n",
    "acionaveis = filtro(planilha_limpa, \"A\")\n",
    "direcionaveis = filtro(planilha_limpa, \"D\")\n",
    "naoacionaveis = filtro(planilha_limpa, \"N\")\n",
    "total = acionaveis + direcionaveis + naoacionaveis\n",
    "pct_a = acionaveis/total\n",
    "pct_d = direcionaveis/total\n",
    "pct_n = naoacionaveis/total\n",
    "\n",
    "print(\"A porcentagem de frases manualmente classificadas foi:\\nAcionáveis = {0:.2f}%\\nDirecionáveis = {1:.2f}%\\nNão Acionáveis = {2:.2f}%\".format(pct_a*100,pct_d*100, pct_n*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, há mais referências para frases Não Acionáveis, em seguida Direcionáveis, e por último Acionáveis, o que pode ser uma boa explicação para as falhas do classificador quanto à distinção da classificação.\n",
    "\n",
    "Analisaremos agora outro cenário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Segundo cenário: análise de frases sarcásticas\n",
    "\n",
    "Queremos agora analisar o comportamento do nosso classificador diante de frases sarcásticas, mas que poderiam ser classificadas de diferentes maneiras.\n",
    "\n",
    "Frase: \"Amei que meu box veio todo rasgado\"\n",
    "\n",
    "Essa frase deveria ser classificada como Acionável. Vamos verificar a classificação automática:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A frase foi classificada como A\n"
     ]
    }
   ],
   "source": [
    "frase2 = \"Amei que meu box veio todo rasgado\"\n",
    "print(\"A frase foi classificada como {0}\".format(classifica_frase(frase2, planilha_limpa)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa frase foi corretamente interpretada. Vamos testar agora para outras frases irônicas com diferentes classificações:\n",
    "\n",
    "Frase 1 = \"A Amazon é ótima, ideal para quem gosta de receber os livros com atraso e com as embalagens mal feitas\"\n",
    "\n",
    "Frase 2 = \"A Amazon é ideal para quem gosta de receber livros com páginas de péssima qualidade e com tradução mal feita\"\n",
    "\n",
    "Frase 3 = \"O livro é ótimo para quem quer perder capacidade intelectual\"\n",
    "\n",
    "A frase 1 deve ser classificada como Acionável, a frase 2 deve ser classificada como Direcionável e a frase 3 como Não Acionável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Frase 1 foi classificada como A\n",
      "A Frase 2 foi classificada como D\n",
      "A Frase 3 foi classificada como N\n"
     ]
    }
   ],
   "source": [
    "frase_ironica_a = \"A Amazon é ótima, ideal para quem gosta de receber os livros com atraso e com as embalagens mal feitas\"\n",
    "frase_ironica_d = \"A Amazon é ideal para quem gosta de receber livros com páginas de péssima qualidade e com tradução mal feita\"\n",
    "frase_ironica_n = \"O livro é ótimo para quem quer perder capacidade intelectual\"\n",
    "print(\"A Frase 1 foi classificada como {0}\\nA Frase 2 foi classificada como {1}\\nA Frase 3 foi classificada como {2}\".format(classifica_frase(frase_ironica_a, planilha_limpa), classifica_frase(frase_ironica_d, planilha_limpa), classifica_frase(frase_ironica_n, planilha_limpa)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nessas classificações, percebemos que as três frases foram corretamente classificadas.\n",
    "\n",
    "Ou seja, podemos concluir que o classificador foi capaz de contornar a ironia contida nas frases! \n",
    "\n",
    "Uma das possíveis explicações para esse fato é de que, como o classificador analisa as palavras individualmente e remove algumas stopwords, uma reclamação quanto ao atraso ou quanto à entrega terá o mesmo efeito se acompanhada de palavras positivas (como ótimo, excelente, incrível) ou negativas (como péssimo, horrível). Vamos verificar essa suspeita?\n",
    "\n",
    "Frase 1 = \"A Amazon é ótima, ideal para quem gosta de receber os livros com atraso e com as embalagens mal feitas\"\n",
    "\n",
    "Frase 4 = \"A Amazon é horrível, péssima para quem gosta de receber os livros sem atraso e sem as embalagens mal feitas\"\n",
    "\n",
    "Note que o sentido da frase se manteve. Será que o classificador irá classificá-las igualmente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Frase 1 foi classificada como A\n",
      "A Frase 4 foi classificada como A\n"
     ]
    }
   ],
   "source": [
    "Frase_1 = \"A Amazon é ótima, ideal para quem gosta de receber os livros com atraso e com as embalagens mal feitas\"\n",
    "Frase_4 = \"A Amazon é horrível, péssima para quem gosta de receber os livros sem atraso e sem as embalagens mal feitas\"\n",
    "print(\"A Frase 1 foi classificada como {0}\\nA Frase 4 foi classificada como {1}\".format(classifica_frase(Frase_1, planilha_limpa), classifica_frase(Frase_4, planilha_limpa)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que o classificador realmente consegue contornar ironias contidas nas frases. Vamos então para o último cenário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Terceiro cenário: análise de frases com dupla negação\n",
    "\n",
    "Queremos saber, por fim, se o classificador é capaz de interpretar corretamente frases com dupla negação. Isto é, diante da ocorrência frequente de uma palavra, ele consegue analisar seu verdadeiro sentido?\n",
    "\n",
    "Tomemos como exemplo as seguintes frases:\n",
    "\n",
    "Frase A = \"Não entendo como não conseguem enviar no prazo e sem chegar tudo rasgado\"\n",
    "\n",
    "Frase D = \"Não entendo como não conseguem fazer páginas com qualidade ou com uma tradução decente\"\n",
    "\n",
    "Frase N = \"Não entendo como pode um autor tão famoso não ter o mínimo de conteúdo para apresentar\"\n",
    "\n",
    "A Frase A deverá ser classificada como Acionável, enquanto a Frase D deverá ser classificada como Direcionável e a frase N como Não Acionável. Vejamos o que o classificador indica:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Frase A foi classificada como A\n",
      "A Frase D foi classificada como D\n",
      "A Frase N foi classificada como N\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frasea = \"Não entendo como não conseguem enviar no prazo e sem chegar tudo rasgado\"\n",
    "frased = \"Não entendo como não conseguem fazer páginas com qualidade ou com uma tradução decente\"\n",
    "frasen = \"Não entendo como pode um autor tão famoso não ter o mínimo de conteúdo para apresentar\"\n",
    "\n",
    "classifica_frase(frase1, planilha_limpa)\n",
    "print(\"A Frase A foi classificada como {0}\\nA Frase D foi classificada como {1}\\nA Frase N foi classificada como {2}\".format(classifica_frase(frasea, planilha_limpa), classifica_frase(frased, planilha_limpa), classifica_frase(frasen, planilha_limpa)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nesse resultado, o classificador automático também não parece apresentar problemas quanto à interpretação de frases com dupla negação. A isso provavelmente se deve o fato de a ocorrência da palavra não apresentar frequência relativa muito parecida nas três classes  (A, D e N). Vamos verificar isso quantitativamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequência relativa de aparecimento da palavra \"não\" em classificações Acionáveis: 0.03103\n",
      "Frequência relativa de aparecimento da palavra \"não\" em classificações Direcionáveis: 0.03103\n",
      "Frequência relativa de aparecimento da palavra \"não\" em classificações Não Acionáveis: 0.03952\n"
     ]
    }
   ],
   "source": [
    "#Frequencia relativa da palavra \"não\" em cada classificação\n",
    "\n",
    "nao_em_a = divisao_categorias(planilha_limpa, \"A\")[2][\"nao\"]\n",
    "nao_em_d = nao_em_a = divisao_categorias(planilha_limpa, \"D\")[2][\"nao\"]\n",
    "nao_em_n = divisao_categorias(planilha_limpa, \"N\")[2][\"nao\"]\n",
    "\n",
    "print('Frequência relativa de aparecimento da palavra \"não\" em classificações Acionáveis: {0:.5f}\\nFrequência relativa de aparecimento da palavra \"não\" em classificações Direcionáveis: {1:.5f}\\nFrequência relativa de aparecimento da palavra \"não\" em classificações Não Acionáveis: {2:.5f}'.format(nao_em_a, nao_em_d, nao_em_n))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, a dupla negação não parece interferir na classificação final da frase. Ainda assim, vale ressaltar que esses são apenas alguns exemplos e não representam a totalidade dos casos.;\n",
    "\n",
    "Uma análise mais fidedigna deveria ser realizada de maneira quantitativa. Porém, por ora, é possível concluir que nos casos de ironia e dupla negação o classificador funciona, apresentando real dificuldade apenas para distinguir frases com ambiguidade de dupla classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Outros Cenários*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensando na utilidade de um classificador Naive-Bayes, destacamos outras aplicações além de um classificador de frases: \n",
    "\n",
    "* Recomendação de oportunidades\n",
    "\n",
    "Na disciplina de Codesign de Aplicativos no Insper, há um projeto de desenvolvimento de um aplicativo comercializável. Um dos projetos consiste no desenvolvimento de um app que irá recomendar oportunidades profissionais e acadêmicas relevantes para um usuário, baseado no seu perfil de interesses. Nesse contexto, a recomendação de conteúdo baseada em um classificador Naive-Bayes seria uma ótima aplicação da ferramenta. Para isso deveríamos considerar que cada interesse e oportunidade são independentes entre si (o que não é necessariamente verdade, mas é uma boa aproximação). Assim, poderíamos calcular a P(Oportunidade|Interesses), que seria a probabilidade de uma oportunidade ser relevante para a pessoa dado os interesses que ela declarou. Nesse caso, cada \"interesse\" receberia um rótulo, e haveria uma probabilidade desse rótulo ocorrer no perfil daquela pessoa (etapa de coleta de dados). Cada \"oportunidade\" também seria um rótulo, mas com uma probabilidade (ocorrência) dentro do app (novamente, coleta de dados). Precisaríamos, ainda, treinar o classificador para identificar quais oportunidades são relevantes para os interesses declarados de cada pessoa. Dessa maneira, poderíamos quantificar os interesses do usuário e recomendar oportunidades mais relevantes com base em seus interesses. Isso é uma boa aplicação para direcionar conteúdos específicos para cada perfil de usuário. \n",
    "\n",
    "(Ideia matemática: P(Oportunidade|Interesses) = P(Interesses|Oportunidade)*P(Oportunidade)/P(Interesses))\n",
    "\n",
    "\n",
    "* Previsão do tempo simples\n",
    "\n",
    "Uma outra aplicação para o classificador Naive-Bayes seria um sistema simplificado de previsão do tempo com base em dados anteriores. Se a base de dados anteriores contiver informações como umidade e temperatura e a condição meteorológica daquele dia (por exemplo, sol, chuva ou nublado), será possível treinar o classificador para prever o tempo de um dia com base na umidade e temperatura coletadas. Isto é: calcularíamos P(Sol|Umidade e Temperatura) = P(Umidade e Temparatura|Sol)*P(Sol)/P(Umidade e Temperatura). Contudo, como iremos comparar P(Sol|Umidade e Temperatura) com P(Chuva|Umidade e Temperatura) e P(Nublado|Umidade e Temperatura), não precisaríamos do fator P(Umidade e Temperatura). Logo, poderíamos indicar qual a condição climática de maior probabilidade para cada dia (ou melhor, para cada par de umidade e temperatura). Portanto, embora as previsões climáticas considerem muitos outros fatores, a aplicação de Naive-Bayes para uma previsão simplificada faz bastante sentido.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações das avaliações entre Treinamento e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenar as planilhas de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar planilha com todas as avaliações (treino e teste)\n",
    "train_test = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar listas com os dados coletados a partir de cada nova divisão de treino e de teste utilizando a função train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progesso:  84%|████████▍ | 84/100 [33:32<05:45, 21.59s/rows]"
     ]
    }
   ],
   "source": [
    "# Dividindo os dados em treinamento e teste usando a função train_test_split da biblioteca sklearn\n",
    "\n",
    "acuracia = []\n",
    "falsos_acionaveis = []\n",
    "falsos_direcionaveis = []\n",
    "falsos_nao_acionaveis = []\n",
    "verdadeiros_acionaveis = []\n",
    "verdadeiros_direcionaveis = []\n",
    "verdadeiros_naoacionaveis = []\n",
    "\n",
    "for i in tqdm(range(0,100),  desc=\"Progesso\", unit=\"rows\"):\n",
    "    \n",
    "    novo_treino, novo_teste = train_test_split(train_test, test_size=250, random_state=None)\n",
    "    resultados = divide_comparativos(novo_treino, novo_teste)\n",
    "    acuracia.append(resultados[0])\n",
    "    falsos_acionaveis.append(resultados[1])\n",
    "    falsos_direcionaveis.append(resultados[2])\n",
    "    falsos_nao_acionaveis.append(resultados[3])\n",
    "    verdadeiros_acionaveis.append(resultados[4])\n",
    "    verdadeiros_direcionaveis.append(resultados[5])\n",
    "    verdadeiros_naoacionaveis.append(resultados[6])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria dataframe com as informações coletadas para cada divisão de planilhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acuracia' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6012\\3191242562.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Cria dataframe com as informações obtidas ao repetir 100 vezes a classificação\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m dados_dic = {\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;34m'Acurácia'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0macuracia\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;34m'Falsos Acionáveis'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfalsos_acionaveis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m'Falsos Direcionáveis'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfalsos_direcionaveis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'acuracia' is not defined"
     ]
    }
   ],
   "source": [
    "#Cria dataframe com as informações obtidas ao repetir 100 vezes a classificação\n",
    "dados_dic = {\n",
    "    'Acurácia': acuracia,\n",
    "    'Falsos Acionáveis': falsos_acionaveis,\n",
    "    'Falsos Direcionáveis': falsos_direcionaveis,\n",
    "    'Falsos Não Acionáveis':falsos_nao_acionaveis,\n",
    "    'Verdadeiros Acionáveis':verdadeiros_acionaveis,\n",
    "    'Verdadeiros Direcionáveis': verdadeiros_direcionaveis,\n",
    "    'Verdadeiros Não Acionáveis': verdadeiros_naoacionaveis\n",
    "}\n",
    "\n",
    "dados_calculados = pd.DataFrame(dados_dic)\n",
    "dados_calculados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria histogramas a partir dos dados coletados nas novas separações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6012\\16947395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Histogramas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Quantidade'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtamanho_fonte\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpeso_fonte\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "tamanho_fonte = 30\n",
    "peso_fonte = 600\n",
    "\n",
    "# Histogramas\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.suptitle('Quantidade', fontsize=tamanho_fonte, fontweight=peso_fonte, y=0.95)\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.hist(dados_calculados[\"Acurácia\"], edgecolor='white') \n",
    "plt.title(\"Histograma Acurácia\")\n",
    "plt.xlabel('Porcentagem de acertos (%)')\n",
    "plt.ylabel('Frequência absoluta')\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.hist(dados_calculados[\"Verdadeiros Acionáveis\"], edgecolor='white') \n",
    "plt.title(\"Histograma Verdadeiros Acionáveis\")\n",
    "plt.ylim(0,30)\n",
    "plt.xlabel('Porcentagem de acertos na categoria \"Acionáveis\" (%)')\n",
    "plt.ylabel('Frequência absoluta')\n",
    "\n",
    "plt.subplot(235) \n",
    "plt.hist(dados_calculados[\"Verdadeiros Não Acionáveis\"], edgecolor='white') \n",
    "plt.ylim(0,30)\n",
    "plt.title(\"Histograma Verdadeiros Não Acionáveis\")\n",
    "plt.xlabel('Porcentagem de acertos na categoria \"Não Acionáveis\" (%)')\n",
    "\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.hist(dados_calculados[\"Verdadeiros Direcionáveis\"], edgecolor='white') \n",
    "plt.ylim(0,30)\n",
    "plt.title(\"Histograma Verdadeiros Direcionáveis\")\n",
    "plt.xlabel('Porcentagem de acertos na categoria \"Direcionáveis\" (%)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusões sobre os histogramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
