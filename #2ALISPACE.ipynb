{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Alison Araujo\n",
    "\n",
    "Nome: Gabrielly Carneiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aliso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aliso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading word_tokenize: Package 'word_tokenize' not\n",
      "[nltk_data]     found in index\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('word_tokenize')\n",
    "stopwordsdic = stopwords.words('portuguese')\n",
    "\n",
    "from spacy import load\n",
    "nlp = load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\aliso\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Insper\\2023.2\\Ciência de Dados\\C.DadosP1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Acionável/Direcionável/Não Acionável</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Para quem gosta de poemas simples, esse é o li...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quando vi o lançamento pensei que finalmente p...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>É incrível como esses escritores e \"intelectua...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Se desse pra devolver eu devolvia, nao é por e...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Futilidade, inutilidade, desperdício de papel,...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  \\\n",
       "0  Para quem gosta de poemas simples, esse é o li...   \n",
       "1  Quando vi o lançamento pensei que finalmente p...   \n",
       "2  É incrível como esses escritores e \"intelectua...   \n",
       "3  Se desse pra devolver eu devolvia, nao é por e...   \n",
       "4  Futilidade, inutilidade, desperdício de papel,...   \n",
       "\n",
       "  Acionável/Direcionável/Não Acionável  \n",
       "0                                    N  \n",
       "1                                    D  \n",
       "2                                    N  \n",
       "3                                    N  \n",
       "4                                    N  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('dados_treino.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Acionável/Direcionável/Não Acionável</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O livro é prolixo, redundante, doentio. Sou su...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bom livro e história envolvente. Porém, o leit...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fala tudo que todos já sabem, sem falar que nã...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ganhei na compra do Kindle. Não é estilo de li...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Custa crer que um livro tão medíocre, embora m...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  \\\n",
       "0  O livro é prolixo, redundante, doentio. Sou su...   \n",
       "1  Bom livro e história envolvente. Porém, o leit...   \n",
       "2  Fala tudo que todos já sabem, sem falar que nã...   \n",
       "3  Ganhei na compra do Kindle. Não é estilo de li...   \n",
       "4  Custa crer que um livro tão medíocre, embora m...   \n",
       "\n",
       "  Acionável/Direcionável/Não Acionável  \n",
       "0                                    N  \n",
       "1                                    D  \n",
       "2                                    N  \n",
       "3                                    N  \n",
       "4                                    N  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('dados_teste.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Acionável/Direcionável/Não Acionável</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Para quem gosta de poemas simples, esse é o li...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quando vi o lançamento pensei que finalmente p...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>É incrível como esses escritores e \"intelectua...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Se desse pra devolver eu devolvia, nao é por e...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Futilidade, inutilidade, desperdício de papel,...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>O autor tenta mostrar outro lado do livro, bus...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Começou boa istoria, no meio um pouco enrolado...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bem, eu nem sei por onde começar. A história é...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Menos do menos, não mais do mesmo. As dicas da...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Meu box veio todo detonado. Fiquei triste porq...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>O e-book possui erro de formatação de capítulo...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a formatação no Kindle é ridícula, problema an...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Comprei dois livros e os dois vieram super ama...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Mensagem  \\\n",
       "0   Para quem gosta de poemas simples, esse é o li...   \n",
       "1   Quando vi o lançamento pensei que finalmente p...   \n",
       "2   É incrível como esses escritores e \"intelectua...   \n",
       "3   Se desse pra devolver eu devolvia, nao é por e...   \n",
       "4   Futilidade, inutilidade, desperdício de papel,...   \n",
       "5   O autor tenta mostrar outro lado do livro, bus...   \n",
       "6   Começou boa istoria, no meio um pouco enrolado...   \n",
       "7   Bem, eu nem sei por onde começar. A história é...   \n",
       "8   Menos do menos, não mais do mesmo. As dicas da...   \n",
       "9   Meu box veio todo detonado. Fiquei triste porq...   \n",
       "10  O e-book possui erro de formatação de capítulo...   \n",
       "11  a formatação no Kindle é ridícula, problema an...   \n",
       "12  Comprei dois livros e os dois vieram super ama...   \n",
       "\n",
       "   Acionável/Direcionável/Não Acionável  \n",
       "0                                     N  \n",
       "1                                     D  \n",
       "2                                     N  \n",
       "3                                     N  \n",
       "4                                     N  \n",
       "5                                     N  \n",
       "6                                     N  \n",
       "7                                     N  \n",
       "8                                     N  \n",
       "9                                     A  \n",
       "10                                    D  \n",
       "11                                    D  \n",
       "12                                    A  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pequena = pd.read_excel('planilha_teste.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na primeira etapa, de classificação manual, consideramos três targets para os reviews: Acionável, Direcionável e Não Acionável. \n",
    "\n",
    "- Acionável: para ser considerado \"acionável\" (\"A\") o review deve ser passível de alguma ação pela Amazon, ou seja, o review deve ser sobre entrega, estado do produto, contato com o suporte, etc. \n",
    "- Direcionável: para o target \"direcionável\" (\"D\") foram considerados comentários relativos à editora, como qualidade do material do livro, preço do livro e do e-book, tradução e edição. \n",
    "- Não Acionáveis: por fim, os não acionáveis (\"NA\") eram comentários relativos ao autor, ao apreço pelo conteúdo do livro, ou comentários irrelavantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funções úteis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar uma função que transforma as frases da planilha em um texto só \n",
    "    #(Será útil para criar o dicionário com as palavras)\n",
    "def transforma_em_string(coluna):\n",
    "    texto = ''\n",
    "    for linha in coluna:\n",
    "        texto += linha + ' '\n",
    "    return texto    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar uma função que limpa todas as pontuações\n",
    "def cleanup(text):\n",
    "    punctuation = r'[´\"\\'!-.:?;$,/~^_=+*&¨%$#@|\\{}()[\\]]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma função que limpa os espaços duplicados\n",
    "def limpa_espaco(text):\n",
    "    punctuation = r'[\\n]'  # Adicione os caracteres desejados aqui\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma função para remover emoji\n",
    "def remove_emoji(text):\n",
    "    text_without_emojis = unidecode(text)\n",
    "    return text_without_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a função de stopwords\n",
    "def stopwords(texto):\n",
    "    palavras = word_tokenize(texto, language='portuguese') # Tokenize é analisar palavras individualmente, basicamente\n",
    "    palavras_sem_stopword = []\n",
    "    for palavra in palavras:\n",
    "        if palavra not in stopwordsdic:\n",
    "            palavras_sem_stopword.append(palavra)\n",
    "    # Reúna as palavras sem stopwords em uma string novamente\n",
    "    texto_sem_stopword = ' '.join(palavras_sem_stopword)\n",
    "    return texto_sem_stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando a função de lematização\n",
    "def lemmat(texto):\n",
    "    doc = nlp(texto)\n",
    "    lemmat_radicais = []\n",
    "    for radicais in doc:\n",
    "        lemmat_radicais.append(radicais.lemma_)\n",
    "    texto_lemmat = ' '.join(lemmat_radicais)    \n",
    "    return texto_lemmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cria uma função que reúna as funções de limpeza\n",
    "def limpa_tudo(mensagem):\n",
    "    #Aplicando a função de limpeza de pontuação\n",
    "    texto = cleanup(mensagem)\n",
    "    #Deixando tudo em letra minúscula\n",
    "    texto = texto.lower()\n",
    "    #Removendo emoji\n",
    "    texto = remove_emoji(texto)\n",
    "    #Aplicando a função de limpeza de espaço\n",
    "    texto = limpa_espaco(texto)\n",
    "    #Removendo stopwords\n",
    "    texto = stopwords(texto)\n",
    "    #Realiza lemmatização\n",
    "    texto = lemmat(texto)          # removi pois demora muito para classificar \n",
    "    return texto\n",
    "\n",
    "\n",
    "# print(limpa_tudo(\"Para quem gosta de poemas simples, esse é o livro ideal! A autora nos faz refletir sobre alguns elementos comuns na vida das mulheres de um jeito bem leve\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Acionável/Direcionável/Não Acionável</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gostar poema simples livro ideal autora fazer ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ver lancamento pensar finalmente poder livrar ...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incrivel escritor intelectual colocar cristian...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de esse pra devolver devolvia nao nao pensar i...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>futilidade inutilidade desperdicio papel tempo...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>mal começar ler ja parei livro falar sobre teo...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>compr livro basear qtd avaliacoe acima media r...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>comprar livro todo paguei fatura ate hoje livr...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>box chegar algum bolha capa algum livro orelha...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>querer saber pq pagar leitor eletronico preco ...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mensagem  \\\n",
       "0    gostar poema simples livro ideal autora fazer ...   \n",
       "1    ver lancamento pensar finalmente poder livrar ...   \n",
       "2    incrivel escritor intelectual colocar cristian...   \n",
       "3    de esse pra devolver devolvia nao nao pensar i...   \n",
       "4    futilidade inutilidade desperdicio papel tempo...   \n",
       "..                                                 ...   \n",
       "495  mal começar ler ja parei livro falar sobre teo...   \n",
       "496  compr livro basear qtd avaliacoe acima media r...   \n",
       "497  comprar livro todo paguei fatura ate hoje livr...   \n",
       "498  box chegar algum bolha capa algum livro orelha...   \n",
       "499  querer saber pq pagar leitor eletronico preco ...   \n",
       "\n",
       "    Acionável/Direcionável/Não Acionável  \n",
       "0                                      N  \n",
       "1                                      D  \n",
       "2                                      N  \n",
       "3                                      N  \n",
       "4                                      N  \n",
       "..                                   ...  \n",
       "495                                    N  \n",
       "496                                    N  \n",
       "497                                    A  \n",
       "498                                    A  \n",
       "499                                    D  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cria uma função que limpa as linhas da planilha e adiciona as mensagens limpas à planilha\n",
    "def mensagem_limpa(planilha):   #recebe a planilha e cria uma nova planilja com a coluna de mensagem \n",
    "                                # com as frases limpas\n",
    "    planilha_limpa = planilha.copy()\n",
    "    planilha_limpa['Mensagem'] = [limpa_tudo(x) for x in list(planilha['Mensagem'])]\n",
    "    return planilha_limpa    #retorna a planilha modificada\n",
    "\n",
    "# print(mensagem_limpa(train))\n",
    "\n",
    "# print(train)\n",
    "#planilha_limpa = mensagem_limpa(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria vocabulário de tudo\n",
    "def cria_vocabulario(coluna_da_planilha):                       #recebe uma coluna da planilha\n",
    "    lista_palavras = transforma_em_string(coluna_da_planilha)\n",
    "    lista_palavras = limpa_tudo(lista_palavras)\n",
    "    lista_palavras = lista_palavras.split()\n",
    "    return lista_palavras     #devolve uma lista com as palavras separadas~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria função que retorna uma lista sem as palavras repetidas\n",
    "def remove_repeticao(lista):\n",
    "    dic = set(lista)\n",
    "    vocabulario = list(dic)\n",
    "    return vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma função que guarda as palavras em pd.Series\n",
    "def cria_pdseries(lista):\n",
    "    tabela = pd.Series(lista)\n",
    "    return tabela\n",
    "\n",
    "#Cria uma função que retorna a frequência absoluta de cada palavra no texto\n",
    "def freq_abs(tabela):\n",
    "    absoluta = tabela.value_counts()\n",
    "    return absoluta\n",
    "\n",
    "#Cria uma função que retorna a frequência relativa de cada palavra no texto\n",
    "def freq_rel(tabela):\n",
    "    relativa = tabela.value_counts(True)\n",
    "    return relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisão categorias\n",
    "## Cria uma função que recebe a planilha e o target e retorna o total de palavras e as tabelas de frequencia absoluta e relativa, nessa ordem\n",
    "def divisao_categorias(planilha, target):\n",
    "    #Etapa de divisão de categorias    \n",
    "    planilha_limpa= mensagem_limpa(planilha)   \n",
    "    # planilha_limpa = planilha_limpa[\"Mensagem\"]                   \n",
    "    filtro_target = planilha_limpa.loc[planilha_limpa['Acionável/Direcionável/Não Acionável'] == target]\n",
    "    vocab_target = cria_vocabulario(filtro_target[\"Mensagem\"])\n",
    "    df_vocab_target = cria_pdseries(vocab_target)\n",
    "    freq_rel_target = freq_rel(df_vocab_target)\n",
    "    freq_abs_target = freq_abs(df_vocab_target)\n",
    "    total_target = freq_abs_target.sum()\n",
    "    #criar vocabulario limpo\n",
    "    vocab_target = remove_repeticao(vocab_target)\n",
    "    return total_target, freq_abs_target, freq_rel_target, vocab_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452,\n",
       " nao            15\n",
       " livro           9\n",
       " querer          7\n",
       " autor           6\n",
       " sao             5\n",
       "                ..\n",
       " casa            1\n",
       " futilidade      1\n",
       " inutilidade     1\n",
       " desperdicio     1\n",
       " folho           1\n",
       " Name: count, Length: 324, dtype: int64,\n",
       " nao            0.033186\n",
       " livro          0.019912\n",
       " querer         0.015487\n",
       " autor          0.013274\n",
       " sao            0.011062\n",
       "                  ...   \n",
       " casa           0.002212\n",
       " futilidade     0.002212\n",
       " inutilidade    0.002212\n",
       " desperdicio    0.002212\n",
       " folho          0.002212\n",
       " Name: proportion, Length: 324, dtype: float64,\n",
       " ['igual',\n",
       "  'precisar',\n",
       "  'dar',\n",
       "  'questoe',\n",
       "  'distribuicao',\n",
       "  'porque',\n",
       "  'homem',\n",
       "  'expandir',\n",
       "  'contribuir',\n",
       "  'comprar',\n",
       "  'tao',\n",
       "  'comecar',\n",
       "  'feminino',\n",
       "  'buscar',\n",
       "  'referencia',\n",
       "  'figurar',\n",
       "  'deixar',\n",
       "  'tempo',\n",
       "  'ir',\n",
       "  'enfim',\n",
       "  'armar',\n",
       "  'erro',\n",
       "  'super',\n",
       "  'algum',\n",
       "  'papel',\n",
       "  'Violao',\n",
       "  'vida',\n",
       "  'tambem',\n",
       "  'lei',\n",
       "  'vomitar',\n",
       "  'Capitulo',\n",
       "  'sempre',\n",
       "  'abandonar',\n",
       "  'problema',\n",
       "  'achar',\n",
       "  'virgem',\n",
       "  'prova',\n",
       "  'negro',\n",
       "  'todo',\n",
       "  'incrivel',\n",
       "  'presta',\n",
       "  'so',\n",
       "  'sete',\n",
       "  'posicao',\n",
       "  'verificavel',\n",
       "  'mundo',\n",
       "  'escritor',\n",
       "  'distopia',\n",
       "  'personagem',\n",
       "  'historio',\n",
       "  'coletanea',\n",
       "  'cada',\n",
       "  'theon',\n",
       "  'extremo',\n",
       "  'futilidade',\n",
       "  'nao',\n",
       "  'ja',\n",
       "  'coisa',\n",
       "  'coincidenciar',\n",
       "  'outro',\n",
       "  'universo',\n",
       "  'retratar',\n",
       "  'unico',\n",
       "  'inutilidade',\n",
       "  'extremamente',\n",
       "  'sr',\n",
       "  'jamais',\n",
       "  'politico',\n",
       "  'futil',\n",
       "  'finalmente',\n",
       "  'pensamento',\n",
       "  'detonar',\n",
       "  'saber',\n",
       "  'preconceituoso',\n",
       "  'nacional',\n",
       "  'influenciavel',\n",
       "  'sao',\n",
       "  'dicar',\n",
       "  'decidir',\n",
       "  'afirmar',\n",
       "  'nojento',\n",
       "  'pessoa',\n",
       "  'mulher',\n",
       "  'poder',\n",
       "  'pouco',\n",
       "  'escravidao',\n",
       "  'colocar',\n",
       "  'irmao',\n",
       "  'interesseiro',\n",
       "  'hejab',\n",
       "  'carater',\n",
       "  'brasileiro',\n",
       "  'tijolo',\n",
       "  'gracar',\n",
       "  'ainda',\n",
       "  'precos',\n",
       "  'folho',\n",
       "  'ignorr',\n",
       "  'solicitar',\n",
       "  'autorar',\n",
       "  'amassar',\n",
       "  'capitulo',\n",
       "  'cristaos',\n",
       "  'tradicional',\n",
       "  'aqui',\n",
       "  'morte',\n",
       "  'fisico',\n",
       "  'direitar',\n",
       "  'americano',\n",
       "  'livro',\n",
       "  'fiquei',\n",
       "  'perda',\n",
       "  'dispensar',\n",
       "  'escroto',\n",
       "  'matheu',\n",
       "  'simples',\n",
       "  'desmerecer',\n",
       "  'assim',\n",
       "  'subjugar',\n",
       "  'precisamo',\n",
       "  'herois',\n",
       "  'diferente',\n",
       "  'falar',\n",
       "  'comum',\n",
       "  'texto',\n",
       "  'finalizar',\n",
       "  'jeito',\n",
       "  'isla',\n",
       "  'compro',\n",
       "  'representacao',\n",
       "  'nunca',\n",
       "  'grande',\n",
       "  'acusar',\n",
       "  'ridicular',\n",
       "  'cristianismo',\n",
       "  'ideal',\n",
       "  'casa',\n",
       "  'tudo',\n",
       "  'trampolim',\n",
       "  'gostar',\n",
       "  'onde',\n",
       "  'artista',\n",
       "  'producente',\n",
       "  'ter',\n",
       "  'puro',\n",
       "  'antigo',\n",
       "  'universidade',\n",
       "  'ponto',\n",
       "  'alfinetar',\n",
       "  'igualmente',\n",
       "  'valor',\n",
       "  'rel',\n",
       "  'baixo',\n",
       "  'ebook',\n",
       "  'pensar',\n",
       "  'qualificar',\n",
       "  'culpar',\n",
       "  'estao',\n",
       "  'identificacao',\n",
       "  'fraco',\n",
       "  '4158',\n",
       "  'cansativo',\n",
       "  'autor',\n",
       "  'totalmente',\n",
       "  'irresponsavel',\n",
       "  'acessivel',\n",
       "  'aler',\n",
       "  'culpa',\n",
       "  'ideiar',\n",
       "  'utilizar',\n",
       "  'avanco',\n",
       "  'mostrar',\n",
       "  'dever',\n",
       "  'amazon',\n",
       "  'mudei',\n",
       "  'elemento',\n",
       "  'menos',\n",
       "  'proximo',\n",
       "  'romance',\n",
       "  'cima',\n",
       "  'estrupo',\n",
       "  'dia',\n",
       "  'chocar',\n",
       "  'traduzir',\n",
       "  'impor',\n",
       "  'fazer',\n",
       "  'arthur',\n",
       "  'acontecer',\n",
       "  'perder',\n",
       "  'atestar',\n",
       "  'desservico',\n",
       "  'produto',\n",
       "  'vier',\n",
       "  'cabeca',\n",
       "  'citar',\n",
       "  'mao',\n",
       "  'imaginar',\n",
       "  'ideologico',\n",
       "  'condenar',\n",
       "  'autora',\n",
       "  'intelectual',\n",
       "  'istor',\n",
       "  'dinheiro',\n",
       "  'ingles',\n",
       "  'estuper',\n",
       "  'propria',\n",
       "  'pudico',\n",
       "  'piorar',\n",
       "  'cheio',\n",
       "  'contrariar',\n",
       "  'chicotinho',\n",
       "  'corriger',\n",
       "  'livrar',\n",
       "  'parte',\n",
       "  'box',\n",
       "  'simplesmente',\n",
       "  'Capitulos',\n",
       "  'precar',\n",
       "  'forma',\n",
       "  'tinta',\n",
       "  'repetitivo',\n",
       "  'aborto',\n",
       "  'pais',\n",
       "  'desperdicio',\n",
       "  'comunista',\n",
       "  'universitar',\n",
       "  'net',\n",
       "  'degradante',\n",
       "  'pra',\n",
       "  'qualidade',\n",
       "  'botar',\n",
       "  'dois',\n",
       "  'distribuir',\n",
       "  'concentimento',\n",
       "  'mal',\n",
       "  'burca',\n",
       "  'pena',\n",
       "  'poema',\n",
       "  'ficar',\n",
       "  'tirar',\n",
       "  'responsabilidader',\n",
       "  'bem',\n",
       "  'resolver',\n",
       "  'gama',\n",
       "  'riqueza',\n",
       "  'protagonista',\n",
       "  'tentar',\n",
       "  'entulho',\n",
       "  'apontar',\n",
       "  'pilula',\n",
       "  'enrolar',\n",
       "  'quase',\n",
       "  'cabeco',\n",
       "  'estudante',\n",
       "  'bdsm',\n",
       "  'formatacao',\n",
       "  'dizer',\n",
       "  'cliente',\n",
       "  'mencao',\n",
       "  'triste',\n",
       "  'chance',\n",
       "  'parametro',\n",
       "  'novidade',\n",
       "  'lugar',\n",
       "  'tanto',\n",
       "  'maiano',\n",
       "  'pq',\n",
       "  'capa',\n",
       "  'invencoes',\n",
       "  'vir',\n",
       "  'lado',\n",
       "  'querer',\n",
       "  'ma',\n",
       "  'lancamento',\n",
       "  'redencao',\n",
       "  'ninguem',\n",
       "  'nivel',\n",
       "  'digital',\n",
       "  'usar',\n",
       "  'referencio',\n",
       "  'desde',\n",
       "  'sobre',\n",
       "  'araber',\n",
       "  'embromar',\n",
       "  'local',\n",
       "  'democratico',\n",
       "  'embotar',\n",
       "  'repugnante',\n",
       "  'radical',\n",
       "  'nada',\n",
       "  'bom',\n",
       "  'compre',\n",
       "  'lugarcomum',\n",
       "  'portugar',\n",
       "  'novo',\n",
       "  'Kindle',\n",
       "  'desrespeitoso',\n",
       "  'devolvia',\n",
       "  'levar',\n",
       "  'estuprar',\n",
       "  'interpretacao',\n",
       "  'obra',\n",
       "  'conteudo',\n",
       "  'daenerys',\n",
       "  'tratar',\n",
       "  'ponta',\n",
       "  'desejar',\n",
       "  'possuir',\n",
       "  'meio',\n",
       "  'refletir',\n",
       "  'demorei',\n",
       "  'ha',\n",
       "  'ver',\n",
       "  'chegar',\n",
       "  'profur',\n",
       "  'devolver',\n",
       "  'seguinte',\n",
       "  'trazer',\n",
       "  'lixo',\n",
       "  'machismo',\n",
       "  'tema',\n",
       "  'ate',\n",
       "  'esperar',\n",
       "  'bibliografico'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Função que recebe a planilha e retorna:\n",
    "# o total de palavras com repetição [0] (int)\n",
    "# a tabela com a frequência absoluta de cada palavra na planilha [1] (Series)\n",
    "# a tabela com a frequência relativa de cada palavra na planilha [2] (Series)\n",
    "# a lista com todas as palavras da planilha sem repetição [3] (list)\n",
    "def divisao_planilhas(planilha):\n",
    "\n",
    "    planilha_limpa= mensagem_limpa(planilha)                      #cria coluna \"Mensagem Limpa\"\n",
    "    planilha_limpa = planilha_limpa[\"Mensagem\"]                   #separa só a coluna \"Mensagem Limpa\"\n",
    "    \n",
    "    vocab_planilha = cria_vocabulario(planilha_limpa)             #lista de palavras na coluna \"Mensagem Limpa\"\n",
    "    df_vocab_planilha = cria_pdseries(vocab_planilha)       #coloca essa lista em um df\n",
    "\n",
    "    freq_abs_planilha = freq_abs(df_vocab_planilha)         #calcula a frequência absoluta de cada palavra\n",
    "    freq_rel_planilha = freq_rel(df_vocab_planilha)         #calcula a frequência relativa de cada palavra\n",
    "\n",
    "    total_planilha = freq_abs_planilha.sum()                #calcula o total de palavras com repetição\n",
    "\n",
    "    vocab_planilha = remove_repeticao(vocab_planilha)\n",
    "\n",
    "    return total_planilha, freq_abs_planilha, freq_rel_planilha, vocab_planilha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de Suavização de LaPlace\n",
    "\n",
    "#vou criar um dicionário com todas as palavras e seus valores de \n",
    "# probabilidade dado target já suavizados\n",
    "# aí vai ficar mais rapido de encontrar os valores\n",
    "# do que ter que suavizar pra cada palavra toda vez\n",
    "# que chamar o loop\n",
    "\n",
    "def suaviza_target (planilha, target):\n",
    "    planilha_limpa = mensagem_limpa(planilha)\n",
    "    coluna_limpa = planilha_limpa[\"Mensagem\"]\n",
    "    \n",
    "    #extraindo dados da planilha\n",
    "    dados_target = divisao_categorias(planilha, target)\n",
    "    frequencias_absolutas = dados_target[1]\n",
    "    qtdd_palavras = dados_target[0]                  #quantidade de palavras no target informado\n",
    "    qtdd_palavras_sem_repeticao = len(dados_target[3]) #quantidade de palavras sem repetição no target informado\n",
    "    \n",
    "    dic = {}   #dicionario com chave de palavra e valor probabilidade condicional\n",
    "    \n",
    "    for frase in coluna_limpa:\n",
    "        frase = frase.split()\n",
    "        for palavra in frase:\n",
    "            if palavra not in dic:\n",
    "                if palavra in frequencias_absolutas:\n",
    "                    freq_abs_palavra = frequencias_absolutas[palavra]\n",
    "                    Prob_palavra_dado_target = (freq_abs_palavra + 1)/(qtdd_palavras + qtdd_palavras_sem_repeticao)\n",
    "                    dic[palavra] = Prob_palavra_dado_target\n",
    "                else:\n",
    "                    freq_abs_palavra = 0\n",
    "                    Prob_palavra_dado_target = (freq_abs_palavra + 1)/(qtdd_palavras + qtdd_palavras_sem_repeticao)\n",
    "                    dic[palavra]= Prob_palavra_dado_target\n",
    "\n",
    "    return dic\n",
    "    \n",
    "    \n",
    "# suaviza_target(train, \"N\")\n",
    "\n",
    "\n",
    "# exemplo de como usar\n",
    "# print(suavizacao(\"absurdo\", \"N\", train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando probabilidade da frase dado target\n",
    "\n",
    "#consegui otimizar\n",
    "# recebe uma frase qualquer (precisa estar limpa)\n",
    "def frase_dado_target(frase, target, planilha):\n",
    "    \n",
    "    prob_frase_dado_classe = 1\n",
    "    # frase = limpa_tudo(frase)\n",
    "    frase =  frase.split()\n",
    "    dic_probabilidades_por_classe = suaviza_target(planilha, target)   #dicionario com as palavras e suas probabilidades condicionais\n",
    "    for palavra in frase:\n",
    "        if palavra in dic_probabilidades_por_classe:\n",
    "            prob_palavra_dado_classe = dic_probabilidades_por_classe[palavra]\n",
    "            prob_frase_dado_classe *= prob_palavra_dado_classe\n",
    "        else:\n",
    "            prob_palavra_dado_classe = 1\n",
    "            prob_frase_dado_classe *= prob_palavra_dado_classe\n",
    "    return prob_frase_dado_classe\n",
    "\n",
    "\n",
    "# frase_dado_target(\"Para quem gosta de poemas simples é o livro ideal, a autora autora faz refletir sobre alguns elementos comuns vida mulheres jeito bem leve\", \"N\", train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agora tem que otimizar essa função de classificador\n",
    "\n",
    "\n",
    "def classificador(frase, planilha):\n",
    "    \n",
    "    #Extraindo as informações\n",
    "    total_train_N = divisao_categorias(train, \"N\")[0]\n",
    "    total_train_D = divisao_categorias(train, \"D\")[0]\n",
    "    total_train_A = divisao_categorias(train, \"A\")[0]\n",
    "    total_train = divisao_planilhas(train)[0]\n",
    "    \n",
    "    #Cálculo das probabilidades\n",
    "    P_frase_dado_A = frase_dado_target(frase, \"A\", planilha)\n",
    "    P_frase_dado_D = frase_dado_target(frase, \"D\", planilha)\n",
    "    P_frase_dado_N = frase_dado_target(frase, \"N\", planilha)\n",
    "    P_train_N = total_train_N/total_train         #probabilidade de estar na categoria N\n",
    "    P_train_D = total_train_D/total_train         #probabilidade de estar na categoria D\n",
    "    P_train_A = total_train_A/total_train         #probabilidade de estar na categoria A\n",
    "    P_A_dado_frase = P_frase_dado_A*P_train_A \n",
    "    P_N_dado_frase = P_frase_dado_N*P_train_N\n",
    "    P_D_dado_frase = P_frase_dado_D*P_train_D\n",
    "        \n",
    "    #Classificação\n",
    "    if P_A_dado_frase > P_D_dado_frase and P_A_dado_frase > P_N_dado_frase:\n",
    "        return \"A\"\n",
    "    elif P_D_dado_frase > P_N_dado_frase and P_D_dado_frase > P_A_dado_frase:\n",
    "        return \"D\"\n",
    "    elif P_N_dado_frase > P_D_dado_frase and P_N_dado_frase > P_A_dado_frase:\n",
    "        return \"N\"\n",
    "    else:\n",
    "        return \"Houve um impasse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando as informações da base de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "####-  DIVISÃO CATEGORIAS TREINO  -####\n",
    "\n",
    "#--- categoria Não Acionável\n",
    "# total_train_N = divisao_categorias(train, \"N\")[0]         #Quantidade total de palavras (incluindo as repetições)\n",
    "# freq_abs_train_N = divisao_categorias(train, \"N\")[1]      #Tabela com as frequencias absolutas das palavras\n",
    "# freq_rel_train_N = divisao_categorias(train, \"N\")[2]      #Tabela com as frequencias relativas das palavras\n",
    "# vocab_train_N = divisao_categorias(train, \"N\")[3]         #Vocabulario de todas as palavras dessa classificação (SEM as repetições)\n",
    "\n",
    "# #--- categoria Direcionável\n",
    "# total_train_D = divisao_categorias(train, \"D\")[0]\n",
    "# freq_abs_train_D = divisao_categorias(train, \"D\")[1]\n",
    "# freq_rel_train_D = divisao_categorias(train, \"D\")[2]\n",
    "# vocab_train_D = divisao_categorias(train, \"D\")[3]              \n",
    "\n",
    "# #--- categoria Acionável\n",
    "# total_train_A = divisao_categorias(train, \"A\")[0]\n",
    "# freq_abs_train_A = divisao_categorias(train, \"A\")[1]\n",
    "# freq_rel_train_A = divisao_categorias(train, \"A\")[2]\n",
    "# vocab_train_A = divisao_categorias(train, \"A\")[3]       \n",
    "\n",
    "# #--- Todas as palavras\n",
    "# total_train = divisao_planilhas(train)[0]\n",
    "# freq_abs_train = divisao_planilhas(train)[1]\n",
    "# freq_rel_train = divisao_planilhas(train)[2]\n",
    "# vocab_train = divisao_planilhas(train)[3]\n",
    "\n",
    "# #### Guardando as palavras em um pd.Series\n",
    "# todas_palavras_train = cria_pdseries(vocab_train)\n",
    "# palavras_train_A = cria_pdseries(vocab_train_A)\n",
    "# palavras_train_N = cria_pdseries(vocab_train_N)\n",
    "# palavras_train_D = cria_pdseries(vocab_train_D)\n",
    "\n",
    "####- PROBABILIDADES DAS CATEGORIAS TREINO -####\n",
    "# prob_trein_N = total_train_N/total_train         #probabilidade de estar na categoria N\n",
    "# prob_trein_D = total_train_D/total_train         #probabilidade de estar na categoria D\n",
    "# prob_trein_A = total_train_A/total_train         #probabilidade de estar na categoria A\n",
    "\n",
    "# prob_trein_N + prob_trein_A + prob_trein_D       #conferindo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavras da base de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####-  DIVISÃO CATEGORIAS TESTE  -####\n",
    "\n",
    "# #--- categoria Não Acionável\n",
    "# total_test_N = divisao_categorias(test, \"N\")[0]         #Quantidade total de palavras (incluindo as repetições)\n",
    "# freq_abs_test_N = divisao_categorias(test, \"N\")[1]      #Tabela com as frequencias absolutas\n",
    "# freq_rel_test_N = divisao_categorias(test, \"N\")[2]      #Tabela com as frequencias relativas\n",
    "# vocab_test_N = divisao_categorias(test, \"N\")[3]         #vocabulario com as palavras dessa categoria (SEM as repetições)\n",
    "\n",
    "# #--- categoria Direcionável\n",
    "# total_test_D = divisao_categorias(test, \"D\")[0]         \n",
    "# freq_abs_test_D = divisao_categorias(test, \"D\")[1]\n",
    "# freq_rel_test_D = divisao_categorias(test, \"D\")[2]\n",
    "# vocab_test_D = divisao_categorias(test, \"D\")[3]  \n",
    "\n",
    "# #--- categoria Acionável\n",
    "# total_test_A = divisao_categorias(test, \"A\")[0]\n",
    "# freq_abs_test_A = divisao_categorias(test, \"A\")[1]\n",
    "# freq_rel_test_A = divisao_categorias(test, \"A\")[2]\n",
    "# vocab_test_A = divisao_categorias(test, \"A\")[3]  \n",
    "\n",
    "# #--- Todas as palavras\n",
    "# total_test = divisao_planilhas(test)[0]\n",
    "# freq_abs_test = divisao_planilhas(test)[1]\n",
    "# freq_rel_test = divisao_planilhas(test)[2]\n",
    "# vocab_test = divisao_planilhas(test)[3]\n",
    "\n",
    "# #### Guardando as palavras em um pd.Series\n",
    "# todas_palavras_test = cria_pdseries(vocab_test)         #cria um dataframe com todas as palavras da planilha de teste\n",
    "# palavras_test_A = cria_pdseries(vocab_test_A)           #cria um df com todas as palavras do target acionavel\n",
    "# palavras_test_N = cria_pdseries(vocab_test_N)           #cria um df com todas as palavras do target nao acionavel\n",
    "# palavras_test_D = cria_pdseries(vocab_test_D)           #cria um df com todas as palvras do target direcionavel\n",
    "# \"\"\"EXPLICAÇÕES\n",
    "# vocab_df [lista] = palavras já limpas\n",
    "\n",
    "# df_vocab_df [tabela] = transforma o vocab_df em tabela\n",
    "\n",
    "# freq_rel_df [tabela] = frequencia relativa de cada palavra\n",
    "# freq_abs_df [tabela] = 1\n",
    "# total_df [int] = quantidade total de palavras\n",
    "# \"\"\"\n",
    "# ####- PROBABILIDADES DAS CATEGORIAS TESTE -####\n",
    "# prob_test_N = total_test_N/total_test    #probabilidade de estar na categoria N\n",
    "# prob_test_D = total_test_D/total_test    #probabilidade de estar na categoria D\n",
    "# prob_test_A = total_test_A/total_test    #probabilidade de estar na categoria A\n",
    "\n",
    "# prob_test_A + prob_test_D + prob_test_N  #conferindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fazer meu classificador classificar todas as frases da planilha de teste\n",
    "\n",
    "def classifica_planilha(planilha):\n",
    "    planilha = mensagem_limpa(planilha)\n",
    "    avaliacoes_limpas = planilha[\"Mensagem\"]\n",
    "    planilha_limpa = planilha.copy()\n",
    "    \n",
    "    # Criar uma lista para armazenar os resultados do classificador\n",
    "    resultados = []\n",
    "\n",
    "    for frase in avaliacoes_limpas:\n",
    "        resultado = classificador(frase, planilha)\n",
    "        resultados.append(resultado)\n",
    "        # print(frase)\n",
    "\n",
    "    # Atribuir a lista de resultados à coluna 'Classificador Automático'\n",
    "    planilha_limpa['Classificador Automático'] = resultados\n",
    "    \n",
    "    return planilha_limpa\n",
    "\n",
    "    \n",
    "\n",
    "planilha_com_classificador_aplicado = classifica_planilha(test)\n",
    "print(planilha_com_classificador_aplicado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45.6, 114, 250, 20)\n"
     ]
    }
   ],
   "source": [
    "#verificando a acurácia\n",
    "\n",
    "def verifica_performance(planilha):\n",
    "\n",
    "    count_comparativo = (planilha['Acionável/Direcionável/Não Acionável'] == planilha['Classificador Automático']).sum() # Conta quantos valores nas duas são correspondentes\n",
    "    total_elementos = len(planilha) #Total de linhas\n",
    "    total_impasses = (planilha['Classificador Automático'] == 'Houve um impasse').sum()\n",
    "\n",
    "    porcentagem_concordancia = (count_comparativo / total_elementos) * 100\n",
    "    \n",
    "    return porcentagem_concordancia, count_comparativo, total_elementos, total_impasses\n",
    "\n",
    "print(verifica_performance(planilha_com_classificador_aplicado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a probabilidade de todas as palavras estarem contidas num texto não é a mesma? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dica: apresentar um grafico com testes mostrando quais limpezas melhoraram a acurácia do nosso classificador (lemmatization, stopwords, etc)\n",
    "\n",
    "REtirar algumas palavras para ver se melhora a qualidade do classificador (exemplo palavra não)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
